{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiDzBoKGwmMZ"
   },
   "source": [
    "# REDES NEURONALES\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeO2xVqBv1fx"
   },
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhzeF2BVvvi7"
   },
   "source": [
    "\n",
    "\n",
    "En esta actividad vamos a utilizar una red neuronal para clasificar imágenes de prendas de ropa. Para ello, utilizaremos Keras con TensorFlow.\n",
    "\n",
    "El dataset a utilizar es Fashion MNIST, un problema sencillo con imágenes pequeñas de ropa, pero más interesante que el dataset de MNIST. Puedes consultar más información sobre el dataset en [este enlace](https://github.com/zalandoresearch/fashion-mnist).\n",
    "\n",
    "El código utilizado para contestar tiene que quedar claramente reflejado en el Notebook. Puedes crear nuevas celdas si así lo deseas para estructurar tu código y sus salidas. A la hora de entregar el notebook, **asegúrate de que los resultados de ejecutar tu código han quedado guardados**. Por ejemplo, a la hora de entrenar una red neuronal tiene que verse claramente un log de los resultados de cada epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gSHr268SwmMa"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zScMKU2OKSPD"
   },
   "source": [
    "En primer lugar vamos a importar el dataset Fashion MNIST (recordad que este es uno de los dataset de entranamiento que estan guardados en keras) que es el que vamos a utilizar en esta actividad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4voG2hxxG4h3"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JphLsCvgKrzb"
   },
   "source": [
    "Llamar a **load_data** en este dataset nos dará dos conjuntos de dos listas, estos serán los valores de entrenamiento y prueba para los gráficos que contienen las prendas de vestir y sus etiquetas.\n",
    "\n",
    "Nota: Aunque en esta actividad lo veis de esta forma, también lo vais a poder encontrar como 4 variables de esta forma: training_images, training_labels, test_images, test_labels = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1muD4PHEG4h6",
    "outputId": "2f6beb46-3176-4adf-a64b-6dab9ea81bbe"
   },
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWGpJqVVLT3Y"
   },
   "source": [
    "Antes de continuar vamos a dar un vistazo a nuestro dataset, para ello vamos a ver una imagen de entrenamiento y su etiqueta o clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "id": "t5a5PlswG4h8",
    "outputId": "2edeb68d-fcba-4f20-c49a-f80a5c51b012"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ef85c7d730>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Label: {}\".format(training_labels[0]))\n",
    "plt.imshow(training_images[0], cmap=\"gray\") # recordad que siempre es preferible trabajar en blanco y negro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCJvZx3MLucY"
   },
   "source": [
    "Habréis notado que todos los valores numericos están entre 0 y 255. Si estamos entrenando una red neuronal, una buena practica es transformar todos los valores entre 0 y 1, un proceso llamado \"normalización\" y afortunadamente en Python es fácil normalizar una lista. Lo puedes hacer de esta manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tojL1BmjG4h_"
   },
   "outputs": [],
   "source": [
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaqXlSMBwmMg"
   },
   "source": [
    "## 1. Información sobre el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0aer8ZZwmMh"
   },
   "source": [
    "Una vez tenemos los datos cargados en memoria, vamos a obtener información sobre los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-im9PnEwmMh"
   },
   "source": [
    "**Pregunta 1.1 *(0.25 puntos)*** ¿Cuántas imágenes hay de *training* y de *test*? ¿Qué tamaño tienen las imágenes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lvP0Y4SCwmMi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images of the train set: 60000\n",
      "Number of images of the test set: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images of the train set: {}\".format(len(training_images)))\n",
    "print(\"Number of images of the test set: {}\".format(len(test_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay un total de 60000 imágenes en el set de entrenamiento y 10000 en el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_images[0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xwp5ljFKwmMj"
   },
   "source": [
    "*Podemos observar que las imágenes con las que estamos trabajando tienen dimensiones de 28x28 píxeles, con una totalidad de 784 píxeles por imagen*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2LsvfHOwmMk"
   },
   "source": [
    "**Pregunta 1.2 *(0.25 puntos)*** Realizar una exploración de las variables que contienen los datos. Describir en qué consiste un example del dataset (qué información se guarda en cada imagen) y describir qué contiene la información en y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3W5rzaGxwmMk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "class_names[training_labels[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaEWKFyvwmMm"
   },
   "source": [
    "*En las etiquetas del conjunto de datos, tanto de entrenamiento como de test, podemos ver qué tipo de prenda contiene cada imagen*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI3IAhOQ8zHi"
   },
   "source": [
    "## 2. Creación del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYUWWsszMAKt"
   },
   "source": [
    "Ahora vamos a definir el modelo, pero antes vamos a repasar algunos comandos y conceptos muy útiles:\n",
    "* **Sequential**: Eso define una SECUENCIA de capas en la red neuronal\n",
    "* **Dense**: Añade una capa de neuronas\n",
    "* **Flatten**: ¿Recuerdas cómo eran las imágenes cuando las imprimiste para poder verlas? Un cuadrado, Flatten toma ese cuadrado y lo convierte en un vector de una dimensión.\n",
    "\n",
    "Cada capa de neuronas necesita una función de activación. Normalmente se usa la función relu en las capas intermedias y softmax en la ultima capa (en problemas de clasificación de más de dos items)\n",
    "* **Relu** significa que \"Si X>0 devuelve X, si no, devuelve 0\", así que lo que hace es pasar sólo valores 0 o mayores a la siguiente capa de la red.\n",
    "* **Softmax** toma un conjunto de valores, y escoge el más grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgBW1yE2MwPp"
   },
   "source": [
    " **Pregunta 2.1 (2 puntos)**. Utilizando Keras, y preparando los datos de X e y como fuera necesario, define y entrena una red neuronal que sea capaz de clasificar imágenes de Fashion MNIST con las siguientes características:\n",
    "\n",
    "* Una hidden layer de tamaño 128, utilizando unidades sigmoid\n",
    "Optimizador Adam.\n",
    "* Durante el entrenamiento, la red tiene que mostrar resultados de loss y accuracy por cada epoch.\n",
    "* La red debe entrenar durante 10 epochs y batch size de 64.\n",
    "* La última capa debe de ser una capa softmax.\n",
    "* Tu red tendría que ser capaz de superar fácilmente 80% de accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizamos los datos de validación para mejorar el accuracy del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = training_images[:5000], training_images[5000:]\n",
    "y_valid, y_train = training_labels[:5000], training_labels[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Diseñamos la red neuronal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "aTaD2QXIORwu"
   },
   "outputs": [],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Compilamos el modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Entrenando y evaluando el modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 997us/step - loss: 0.5193 - accuracy: 0.8197 - val_loss: 0.3901 - val_accuracy: 0.8630\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 930us/step - loss: 0.3875 - accuracy: 0.8628 - val_loss: 0.3365 - val_accuracy: 0.8812\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 915us/step - loss: 0.3505 - accuracy: 0.8737 - val_loss: 0.3222 - val_accuracy: 0.8824\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 913us/step - loss: 0.3237 - accuracy: 0.8828 - val_loss: 0.2915 - val_accuracy: 0.8884\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 920us/step - loss: 0.3071 - accuracy: 0.8887 - val_loss: 0.2754 - val_accuracy: 0.8982\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 981us/step - loss: 0.2925 - accuracy: 0.8939 - val_loss: 0.2679 - val_accuracy: 0.9012\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2803 - accuracy: 0.8965 - val_loss: 0.2669 - val_accuracy: 0.9000\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2673 - accuracy: 0.9023 - val_loss: 0.2468 - val_accuracy: 0.9118\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2595 - accuracy: 0.9058 - val_loss: 0.2502 - val_accuracy: 0.9066\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 959us/step - loss: 0.2515 - accuracy: 0.9068 - val_loss: 0.2789 - val_accuracy: 0.8972\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_images, training_labels, epochs=10, batch_size=64, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bxr5hTKYOQnK"
   },
   "source": [
    "Para concluir el entrenamiento de la red neuronal, una buena práctica es evaluar el modelo para ver si la precisión de entrenamiento es real\n",
    "\n",
    "**pregunta 2.2 (0.5 puntos)**: Evalúa el modelo con las imágenes y etiquetas test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 611us/step - loss: 0.4016 - accuracy: 0.8599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4015773832798004, 0.8598999977111816]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygMVnmSYO83U"
   },
   "source": [
    "\n",
    "## 3: Funcionamiento de las predicción de la red neuronal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMa-GR0Kvcqh"
   },
   "source": [
    "Ahora vamos a explorar el código con una serie de ejercicios para alcanzar un grado de comprensión mayor sobre las redes neuronales y su entrenamiento.\n",
    "\n",
    "Sigue los siguientes pasos: \n",
    "\n",
    "* Crea una variable llamada **classifications** para construir un clasificador con las imágenes de prueba, para ello puedes utilizar la función predict sobre el conjunto de test\n",
    "* Imprime con la función print la primera entrada en las clasificaciones. \n",
    "\n",
    "**pregunta 3.1 (0.25 puntos)**, el resultado al imprimirlo es un vector de números, \n",
    "* ¿Por qué crees que ocurre esto? ¿Qué representa este vector de números?\n",
    "\n",
    "**pregunta 3.2 (0.25 puntos)**\n",
    "* ¿Cúal es la clase de la primera entrada de la variable **classifications**? La respuesta puede ser un número o su etiqueta/clase equivalente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 490us/step\n"
     ]
    }
   ],
   "source": [
    "classificatios = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "b-mL-h4xQhCm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.8523502e-07, 2.5689164e-09, 2.5453326e-05, 4.1483427e-06, 2.9091515e-07, 3.1529448e-03, 3.9322586e-05, 1.4762512e-02, 3.9736265e-06, 9.8201114e-01], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificatios[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvbVC9gaQhMY"
   },
   "source": [
    "Tu respuesta a la pregunta 3.1 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La función .predict() de keras aplicada al conjunto de test nos proporciona un array de con las probabilidades de que se trate de una categoría u otra. En este caso podemos observar como la etiqueta más probable es efectivamente la de la etiqueta número 9, \"ankle boot\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRWo-75tdgv0"
   },
   "source": [
    "Tu respuesta a la pregunta 3.2 aquí:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay que tener en cuenta que esta función está pensada para las predicciones del modelo\n",
    "def clase_mas_probable(i):\n",
    "    if i >= 0 and i < 10:\n",
    "        print(\"La clase más probable para la imagen número {} es {} con la etiqueta número {}\".format(i + 1, class_names[list(classificatios[i]).index(max(classificatios[i]))], list(classificatios[i]).index(max(classificatios[i]))))\n",
    "        plt.imshow(training_images[i], cmap=\"gray\")\n",
    "    else:\n",
    "        print(\"Not in the wardrobe\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clase más probable para la imagen número 1 es Ankle boot con la etiqueta número 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clase_mas_probable(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[test_labels[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiQ8qAzhRQ4L"
   },
   "source": [
    "## 4: Impacto variar el número de neuronas en las capas ocultas\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lsqive4ivMF9"
   },
   "source": [
    "En este ejercicio vamos a experimentar con nuestra red neuronal cambiando el numero de neuronas por 512 y por 1024. Para ello, utiliza la red neuronal de la pregunta 1, y en su capa oculta cambia las 128 neuronas por:\n",
    "\n",
    "* **512 neuronas en la capa oculta\n",
    "* **1024 neuronas en la capa oculta\n",
    "\n",
    "Entrena la red en ambos casos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 512 Neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "cdP8ZwuaUV93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4838 - accuracy: 0.8298 - val_loss: 0.3873 - val_accuracy: 0.8592\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3604 - accuracy: 0.8696 - val_loss: 0.2891 - val_accuracy: 0.8940\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3233 - accuracy: 0.8813 - val_loss: 0.3041 - val_accuracy: 0.8846\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2990 - accuracy: 0.8899 - val_loss: 0.2637 - val_accuracy: 0.9038\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2807 - accuracy: 0.8966 - val_loss: 0.2596 - val_accuracy: 0.9058\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2672 - accuracy: 0.9002 - val_loss: 0.2313 - val_accuracy: 0.9158\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2526 - accuracy: 0.9066 - val_loss: 0.2261 - val_accuracy: 0.9172\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2422 - accuracy: 0.9094 - val_loss: 0.2234 - val_accuracy: 0.9208\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2321 - accuracy: 0.9140 - val_loss: 0.2017 - val_accuracy: 0.9220\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2203 - accuracy: 0.9183 - val_loss: 0.1919 - val_accuracy: 0.9270\n"
     ]
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(512, activation=\"relu\"),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=10, batch_size=64, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 988us/step - loss: 0.3241 - accuracy: 0.8871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32405558228492737, 0.8870999813079834]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 908us/step\n"
     ]
    }
   ],
   "source": [
    "classificatios = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clase más probable para la imagen número 1 es Ankle boot con la etiqueta número 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clase_mas_probable(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1024 Neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.4727 - accuracy: 0.8324 - val_loss: 0.4272 - val_accuracy: 0.8416\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.3576 - accuracy: 0.8695 - val_loss: 0.3070 - val_accuracy: 0.8856\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.3227 - accuracy: 0.8808 - val_loss: 0.2746 - val_accuracy: 0.8980\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.2940 - accuracy: 0.8906 - val_loss: 0.2808 - val_accuracy: 0.8962\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.2779 - accuracy: 0.8966 - val_loss: 0.2634 - val_accuracy: 0.9020\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.2630 - accuracy: 0.9022 - val_loss: 0.2414 - val_accuracy: 0.9102\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.2481 - accuracy: 0.9068 - val_loss: 0.2277 - val_accuracy: 0.9162\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.2362 - accuracy: 0.9125 - val_loss: 0.2059 - val_accuracy: 0.9216\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.2282 - accuracy: 0.9135 - val_loss: 0.2326 - val_accuracy: 0.9104\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.2170 - accuracy: 0.9186 - val_loss: 0.2035 - val_accuracy: 0.9238\n"
     ]
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(1024, activation=\"relu\"),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=10, batch_size=64, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3460221588611603, 0.8787000179290771]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "classificatios = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wG0h2HL-Uj93"
   },
   "source": [
    "**pregunta 4.1 (0.5 puntos)**: ¿Cuál es el impacto que tiene la red neuronal? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkZYq4xBvnrS"
   },
   "source": [
    "*Podemos observar una ínfima mejora en el modelo y un tiempo de ejecución superior, pasando de tardar 39 segundos a casi 60. No merece la pena aumentar el número de neuronas dentro de la misma capa para este problema en concreto.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora entrenais el modelo de esta forma (con 512 y 1024 neuronas en la capa oculta) y volveis a ejecutar el predictor guardado en la variable **classifications**, escribir el código del clasificador del ejercicio 1 de nuevo e imprimid el primer objeto guardado en la variable classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "RdJHl3V-G4iS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clase más probable para la imagen número 1 es Ankle boot con la etiqueta número 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clase_mas_probable(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-NpUI9EVkVz"
   },
   "source": [
    "\n",
    "**pregunta 4.2 (0.25 puntos)**: \n",
    "\n",
    "* ¿En qué clase está clasificado ahora la primera prenda de vestir de la variable classifications?\n",
    "\n",
    "**pregunta 4.3 (0.25 puntos)**: \n",
    "\n",
    "* ¿Por qué crees que ha ocurrido esto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3NfwdOGZcAa"
   },
   "source": [
    "Tu respuesta a la pregunta 4.2 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La primera prenda de vestir la clasifica correctamente como un Ankle boot*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFmfpxE1ZcJx"
   },
   "source": [
    "Tu respuesta a la pregunta 4.3 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tanto con 512 como 1024 neuronas en la capa oculta podemos ver que el modelo predice que la primera imagen del set de test es un Ankle boot. Esto es así porque con la cantidad y sencillez de los datos con los que estamos trabajando, aumentar el número de nueronas de la capa oculta no mejora practicamente nada el resultado del modelo*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59eM76O1YekZ"
   },
   "source": [
    "## 5: Capa Flatten\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6LGnSxBu-ww"
   },
   "source": [
    "En este ejercicio vamos a ver que ocurre cuando quitamos la capa flatten, para ello, escribe la red neuronal de la pregunta 1 y no pongas la capa Flatten.\n",
    "\n",
    "**pregunta 5 (0.5 puntos):** ¿Puedes explicar a qué se debe el error que da?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ecfEVKEuG4iU"
   },
   "outputs": [],
   "source": [
    "# model= keras.models.Sequential([\n",
    "#     # keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "#     keras.layers.Dense(128, activation=\"relu\"),\n",
    "#     keras.layers.Dense(len(np.unique(training_labels)), activation=\"softmax\")\n",
    "# ])\n",
    "\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "#             optimizer= \"adam\",\n",
    "#             metrics =[\"accuracy\"])\n",
    "\n",
    "# history = model.fit(training_images, training_labels, epochs=10, batch_size=64, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aNmrkkOZN6D"
   },
   "source": [
    "Tu respuesta a la pregunta 5 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*El modelo fracasa en entrenar con los datos porque la capa de entrada no es unidimensional. Necesitamos .Flatten() para convertir los píxeles de la imagen, que consta de una matriz bidimiensional de 28x28, en otra matriz unidimensional de 784x1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f37cIr81ZYJj"
   },
   "source": [
    "## 6: Número de neuronas de la capa de salida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zk1xYVAQu0wN"
   },
   "source": [
    "Considerad la capa final, la de salida de la red neuronal de la pregunta 1.\n",
    "\n",
    "**pregunta 6.1 (0.25 puntos)**: ¿Por qué son 10 las neuronas de la última capa?\n",
    "\n",
    "**pregunta 6.2 (0.25 puntos)**: ¿Qué pasaría si tuvieras una cantidad diferente a 10? \n",
    "\n",
    "Por ejemplo, intenta entrenar la red con 5, para ello utiliza la red neuronal de la pregunta 1 y cambia a 5 el número de neuronas en la última capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "FhbZkppYZOCS"
   },
   "outputs": [],
   "source": [
    "# model= keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "#     keras.layers.Dense(128, activation=\"relu\"),\n",
    "#     keras.layers.Dense(5, activation=\"softmax\")\n",
    "# ])\n",
    "\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "#             optimizer= \"adam\",\n",
    "#             metrics =[\"accuracy\"])\n",
    "\n",
    "# history = model.fit(training_images, training_labels, epochs=10, batch_size=64, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLsQcq-6aUoD"
   },
   "source": [
    "Tu respuestas a la pregunta 6.1 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*En la capa de salida necesitamos tantas neuronas como clases vayamos a predecir. Por eso al haber 10 clases necesitaremos 10 neuronas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1f_7ZFeaUu6"
   },
   "source": [
    "Tu respuestas a la pregunta 6.2 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Al tener un número de neuronas diferente al número de clases, el modelo simplemente sería incapaz de entrenar y aprender*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNIBCkshaf2y"
   },
   "source": [
    "## 7: Aumento de epoch y su efecto en la red neuronal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg8tTqYPuwGc"
   },
   "source": [
    "En este ejercicio vamos a ver el impacto de aumentar los epoch en el entrenamiento. Usando la red neuronal de la pregunta 1:\n",
    "\n",
    "**pregunta 7.1 (0.15 puntos)**\n",
    "* Intentad 15 epoch para su entrenamiento, probablemente obtendras un modelo con una pérdida mucho mejor que el que tiene 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Cb5vk_imG4iZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "938/938 [==============================] - 2s 1ms/step - loss: 0.5225 - accuracy: 0.8188 - val_loss: 0.3892 - val_accuracy: 0.8666\n",
      "Epoch 2/15\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3871 - accuracy: 0.8608 - val_loss: 0.3423 - val_accuracy: 0.8778\n",
      "Epoch 3/15\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3483 - accuracy: 0.8743 - val_loss: 0.3438 - val_accuracy: 0.8720\n",
      "Epoch 4/15\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3227 - accuracy: 0.8839 - val_loss: 0.2986 - val_accuracy: 0.8968\n",
      "Epoch 5/15\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3054 - accuracy: 0.8886 - val_loss: 0.2981 - val_accuracy: 0.8918\n",
      "Epoch 6/15\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2899 - accuracy: 0.8940 - val_loss: 0.2676 - val_accuracy: 0.9046\n",
      "Epoch 7/15\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2784 - accuracy: 0.8981 - val_loss: 0.2505 - val_accuracy: 0.9090\n",
      "Epoch 8/15\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2676 - accuracy: 0.9010 - val_loss: 0.2457 - val_accuracy: 0.9080\n",
      "Epoch 9/15\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2595 - accuracy: 0.9037 - val_loss: 0.2285 - val_accuracy: 0.9168\n",
      "Epoch 10/15\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2488 - accuracy: 0.9081 - val_loss: 0.2351 - val_accuracy: 0.9088\n",
      "Epoch 11/15\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2385 - accuracy: 0.9107 - val_loss: 0.2257 - val_accuracy: 0.9170\n",
      "Epoch 12/15\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2328 - accuracy: 0.9140 - val_loss: 0.2276 - val_accuracy: 0.9108\n",
      "Epoch 13/15\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2262 - accuracy: 0.9161 - val_loss: 0.2018 - val_accuracy: 0.9260\n",
      "Epoch 14/15\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2177 - accuracy: 0.9193 - val_loss: 0.2021 - val_accuracy: 0.9262\n",
      "Epoch 15/15\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2122 - accuracy: 0.9212 - val_loss: 0.2020 - val_accuracy: 0.9234\n",
      "313/313 [==============================] - 0s 801us/step - loss: 0.3466 - accuracy: 0.8783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3466321527957916, 0.8783000111579895]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=15, batch_size=64, validation_data=(X_valid, y_valid))\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pregunta 7.2 (0.15 puntos)**\n",
    "* Intenta ahora con 30 epoch para su entrenamiento, podrás ver que el valor de la pérdida deja de disminuir, y a veces aumenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "I9jQ26Gda5cv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.5230 - accuracy: 0.8189 - val_loss: 0.4168 - val_accuracy: 0.8526\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3893 - accuracy: 0.8611 - val_loss: 0.3350 - val_accuracy: 0.8824\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3507 - accuracy: 0.8733 - val_loss: 0.3124 - val_accuracy: 0.8890\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3222 - accuracy: 0.8845 - val_loss: 0.3016 - val_accuracy: 0.8908\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3044 - accuracy: 0.8894 - val_loss: 0.2844 - val_accuracy: 0.8934\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2888 - accuracy: 0.8946 - val_loss: 0.2859 - val_accuracy: 0.8948\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2766 - accuracy: 0.8990 - val_loss: 0.2431 - val_accuracy: 0.9086\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2666 - accuracy: 0.9017 - val_loss: 0.2380 - val_accuracy: 0.9100\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2554 - accuracy: 0.9048 - val_loss: 0.2455 - val_accuracy: 0.9104\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2476 - accuracy: 0.9083 - val_loss: 0.2336 - val_accuracy: 0.9178\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2378 - accuracy: 0.9122 - val_loss: 0.2140 - val_accuracy: 0.9222\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 1s 964us/step - loss: 0.2293 - accuracy: 0.9146 - val_loss: 0.2225 - val_accuracy: 0.9202\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 1s 919us/step - loss: 0.2231 - accuracy: 0.9167 - val_loss: 0.1996 - val_accuracy: 0.9264\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 1s 952us/step - loss: 0.2174 - accuracy: 0.9194 - val_loss: 0.1992 - val_accuracy: 0.9288\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 1s 998us/step - loss: 0.2096 - accuracy: 0.9224 - val_loss: 0.1864 - val_accuracy: 0.9324\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 1s 932us/step - loss: 0.2035 - accuracy: 0.9244 - val_loss: 0.1857 - val_accuracy: 0.9350\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 1s 899us/step - loss: 0.1984 - accuracy: 0.9255 - val_loss: 0.1944 - val_accuracy: 0.9252\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 1s 887us/step - loss: 0.1931 - accuracy: 0.9281 - val_loss: 0.1702 - val_accuracy: 0.9370\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1885 - accuracy: 0.9303 - val_loss: 0.1723 - val_accuracy: 0.9384\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 1s 929us/step - loss: 0.1837 - accuracy: 0.9313 - val_loss: 0.1648 - val_accuracy: 0.9388\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 1s 940us/step - loss: 0.1767 - accuracy: 0.9338 - val_loss: 0.1635 - val_accuracy: 0.9384\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 1s 899us/step - loss: 0.1731 - accuracy: 0.9350 - val_loss: 0.1689 - val_accuracy: 0.9376\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 1s 918us/step - loss: 0.1704 - accuracy: 0.9359 - val_loss: 0.1578 - val_accuracy: 0.9390\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 1s 903us/step - loss: 0.1692 - accuracy: 0.9370 - val_loss: 0.1391 - val_accuracy: 0.9464\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 1s 899us/step - loss: 0.1604 - accuracy: 0.9404 - val_loss: 0.1444 - val_accuracy: 0.9464\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 1s 953us/step - loss: 0.1581 - accuracy: 0.9402 - val_loss: 0.1367 - val_accuracy: 0.9478\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 1s 910us/step - loss: 0.1542 - accuracy: 0.9419 - val_loss: 0.1313 - val_accuracy: 0.9504\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 1s 902us/step - loss: 0.1509 - accuracy: 0.9435 - val_loss: 0.1354 - val_accuracy: 0.9518\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 1s 881us/step - loss: 0.1485 - accuracy: 0.9445 - val_loss: 0.1253 - val_accuracy: 0.9558\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 1s 879us/step - loss: 0.1449 - accuracy: 0.9452 - val_loss: 0.1402 - val_accuracy: 0.9494\n",
      "313/313 [==============================] - 0s 548us/step - loss: 0.3858 - accuracy: 0.8795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38581305742263794, 0.8794999718666077]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=30, batch_size=64, validation_data=(X_valid, y_valid))\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pregunta 7.3 (0.20 puntos)**\n",
    "* ¿Por qué piensas que ocurre esto? Explica tu respuesta y da el nombre de este efecto si lo conoces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fs0fjzH4bmSR"
   },
   "source": [
    "Tu respuesta a la pregunta 7.3 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*El accuracy de ambos modelos con 15 y 30 epochs respectivamente, es practicamente el mismo. Lo que sí podemos apreciar es un empeoramiento del coste a mayor número de epochs. Esto puede significar que el modelo está sufriendo de overfitting ya que no hay suficientes datos como para dedicarles tanto tiempo y ciclos de aprendizaje para  aprenderlos.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlIgNG4Yb_N6"
   },
   "source": [
    "## 8: Early stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06rrpDXqupAA"
   },
   "source": [
    "En el ejercicio anterior, cuando entrenabas con epoch extras, tenías un problema en el que tu pérdida podía cambiar. Puede que te haya llevado un poco de tiempo esperar a que el entrenamiento lo hiciera,  y puede que hayas pensado \"¿no estaría bien si pudiera parar el entrenamiento cuando alcance un valor deseado?\", es decir, una precisión del 85% podría ser suficiente para ti, y si alcanzas eso después de 3 epoch, ¿por qué sentarte a esperar a que termine muchas más épocas? Como cualquier otro programa existen formas de parar la ejecución\n",
    "\n",
    "A partir del código de ejemplo, hacer una nueva función que tenga en cuenta la perdida (loss) y que pueda parar el código para evitar que ocurra el efeto secundario que vimos en el ejercicio 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "b5UwceFUG4ic"
   },
   "outputs": [],
   "source": [
    "### Ejemplo de código\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('accuracy')> 0.85):\n",
    "                  print(\"\\nAlcanzado el 85% de precisión, se cancela el entrenamiento!!\")\n",
    "                  self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "29LSfdOvc270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "Epoch 1/50\n",
      "938/938 [==============================] - 1s 951us/step - loss: 0.5208 - accuracy: 0.8201\n",
      "Epoch 2/50\n",
      "925/938 [============================>.] - ETA: 0s - loss: 0.3914 - accuracy: 0.8614\n",
      "Alcanzado el 85% de precisión, se cancela el entrenamiento!!\n",
      "938/938 [==============================] - 1s 872us/step - loss: 0.3912 - accuracy: 0.8616\n",
      "313/313 [==============================] - 0s 477us/step - loss: 0.4239 - accuracy: 0.8530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42390766739845276, 0.8529999852180481]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "### Tu código de la función callback para parar el entrenamiento de la red neuronal al 40% de loss aqui: ###\n",
    "\n",
    "callbacks = myCallback()\n",
    "# mnist = tf.keras.datasets.fashion_mnist\n",
    "# (training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# training_images = training_images/255.0\n",
    "# test_images = test_images/255.0\n",
    "\n",
    "\n",
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=50, batch_size=64, callbacks=[callbacks])\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Bjd8wGKccrn"
   },
   "source": [
    "**Ejercicio 8 *(0.75 puntos)***: Completa el siguiente código con una clase callback que una vez alcanzado el 40% de perdida detenga el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ejemplo de código\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('loss') < 0.4):\n",
    "                  print(\"\\nAlcanzado el 40 de pérdida, se cancela el entrenamiento!!\")\n",
    "                  self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "Epoch 1/50\n",
      "938/938 [==============================] - 1s 858us/step - loss: 0.5251 - accuracy: 0.8170\n",
      "Epoch 2/50\n",
      "911/938 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8629\n",
      "Alcanzado el 40 de pérdida, se cancela el entrenamiento!!\n",
      "938/938 [==============================] - 1s 833us/step - loss: 0.3839 - accuracy: 0.8631\n",
      "313/313 [==============================] - 0s 448us/step - loss: 0.4060 - accuracy: 0.8538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4060156047344208, 0.8537999987602234]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "### Tu código de la función callback para parar el entrenamiento de la red neuronal al 40% de loss aqui: ###\n",
    "\n",
    "callbacks = myCallback()\n",
    "# mnist = tf.keras.datasets.fashion_mnist\n",
    "# (training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# training_images = training_images/255.0\n",
    "# test_images = test_images/255.0\n",
    "\n",
    "\n",
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=50, batch_size=64, callbacks=[callbacks])\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_yZ9B8gTFqR"
   },
   "source": [
    "## 9. Unidades de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuVNxmXSTFqR"
   },
   "source": [
    "En este ejercicio, vamos a evaluar la importancia de utilizar las unidades de activación adecuadas. Como hemos visto en clase, funciones de activación como sigmoid han dejado de utilizarse en favor de otras como ReLU.\n",
    "\n",
    "**Ejercicio 9 *(0.75 puntos)***: Partiendo de una red sencilla como la desarrollada en el Trabajo 1, escribir un breve análisis comparando la utilización de unidades sigmoid y ReLU (por ejemplo, se pueden comentar aspectos como velocidad de convergencia, métricas obtenidas...). Explicar por qué pueden darse estas diferencias. Opcionalmente, comparar con otras activaciones disponibles en Keras.\n",
    "\n",
    "*Pista: Usando redes más grandes se hace más sencillo apreciar las diferencias. Es mejor utilizar al menos 3 o 4 capas densas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ejemplo de código\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs={}):\n",
    "            perdida = 0.4\n",
    "            precision = 0.9\n",
    "            if(logs.get('accuracy') > precision and logs.get('loss') < perdida):\n",
    "                  print(\"\\nAlcanzado el {}% de precisión y {}% de pérdida, se cancela el entrenamiento!!\".format(precision, perdida))\n",
    "                  self.model.stop_training = True\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "hoYUajTuTFqS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.5171 - accuracy: 0.8150\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3735 - accuracy: 0.8624\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3317 - accuracy: 0.8777\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3098 - accuracy: 0.8851\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2950 - accuracy: 0.8888\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2820 - accuracy: 0.8949\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2691 - accuracy: 0.8991\n",
      "Epoch 8/50\n",
      "910/938 [============================>.] - ETA: 0s - loss: 0.2581 - accuracy: 0.9031\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2579 - accuracy: 0.9031\n",
      "313/313 [==============================] - 0s 506us/step - loss: 0.3535 - accuracy: 0.8757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3534862995147705, 0.8756999969482422]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=50, batch_size=64, callbacks=[callbacks])\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.8914 - accuracy: 0.6495\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4623 - accuracy: 0.8367\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3937 - accuracy: 0.8617\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3634 - accuracy: 0.8716\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3393 - accuracy: 0.8779\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3200 - accuracy: 0.8854\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3083 - accuracy: 0.8899\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2934 - accuracy: 0.8932\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2853 - accuracy: 0.8973\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2744 - accuracy: 0.9000\n",
      "Epoch 11/50\n",
      "899/938 [===========================>..] - ETA: 0s - loss: 0.2687 - accuracy: 0.9032\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2678 - accuracy: 0.9035\n",
      "313/313 [==============================] - 0s 536us/step - loss: 0.3556 - accuracy: 0.8746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3556302785873413, 0.8745999932289124]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(128, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(128, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(128, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=50, batch_size=64, callbacks=[callbacks])\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.5187 - accuracy: 0.8153\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.3987 - accuracy: 0.8555\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.3593 - accuracy: 0.8682\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.3376 - accuracy: 0.8757\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.3244 - accuracy: 0.8795\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.3096 - accuracy: 0.8856\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.3001 - accuracy: 0.8877\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.2874 - accuracy: 0.8926\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.2835 - accuracy: 0.8940\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.2757 - accuracy: 0.8963\n",
      "Epoch 11/50\n",
      "935/938 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.9001\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.2674 - accuracy: 0.9000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3431 - accuracy: 0.8778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34311097860336304, 0.8777999877929688]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(512, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(512, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(512, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(512, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=50, batch_size=64, callbacks=[callbacks])\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La comparación entre el uso de la función de activación sigmoid y ReLU en una red neuronal sencilla puede tener varias diferencias en términos de velocidad de convergencia y rendimiento del modelo.*\n",
    "\n",
    "*En general, la función de activación ReLU se ha demostrado que converge más rápido en comparación con la función sigmoid en la mayoría de los casos, esto se debe principalmente a que la función ReLU no presenta saturación en la región positiva, es decir, la derivada nunca es cero, mientras que en sigmoid si hay una región en la que la derivada es muy pequeña (cercana a cero) y puede hacer que el entrenamiento sea lento.*\n",
    "\n",
    "*Además, la función ReLU ha demostrado ser más efectiva en la prevención del sobreajuste (overfitting), lo que se debe a que la función ReLU puede disminuir la correlación entre las neuronas adyacentes, lo que reduce la dependencia de las neuronas entre sí y, por lo tanto, ayuda a prevenir el sobreajuste.*\n",
    "\n",
    "*En términos de rendimiento del modelo, la función ReLU también puede proporcionar resultados ligeramente mejores en comparación con la función sigmoid. Esto se debe a que la función ReLU permite la propagación de gradientes más fuertes en la red neuronal, lo que puede mejorar la capacidad de la red para aprender representaciones abstractas de los datos.*\n",
    "\n",
    "*En cuanto a otras funciones de activación disponibles en Keras, hay muchas opciones diferentes, cada una con sus ventajas y desventajas. Por ejemplo, la función de activación tanh (tangente hiperbólica) se utiliza comúnmente en redes neuronales porque puede proporcionar resultados ligeramente mejores que sigmoid en algunos casos. También hay otras funciones de activación como la función softmax, la función ELU (exponential linear unit) y la función Swish, que han demostrado ser efectivas en diferentes aplicaciones.*\n",
    "\n",
    "*Sintetizando, la función de activación ReLU puede ser una mejor opción en comparación con sigmoid en la mayoría de los casos, debido a su rapidez de convergencia y capacidad para prevenir el sobreajuste. Sin embargo, es importante tener en cuenta que cada función de activación tiene sus propias ventajas y desventajas, y debe seleccionarse de acuerdo con la tarea específica que se esté abordando*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pu6RbUFKTFqT"
   },
   "source": [
    "## 10. Inicialización de parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Abmm05UPTFqU"
   },
   "source": [
    "En este ejercicio, vamos a evaluar la importancia de una correcta inicialización de parámetros en una red neuronal.\n",
    "\n",
    "**Ejercicio 10 *(0.75 puntos)***: Partiendo de una red similar a la del ejercicio anterior (usando ya ReLUs), comentar las diferencias que se aprecian en el entrenamiento al utilizar distintas estrategias de inicialización de parámetros. Para ello, inicializar todas las capas con las siguientes estrategias, disponibles en Keras, y analizar sus diferencias:\n",
    "\n",
    "* Inicialización con ceros.\n",
    "* Inicialización con una variable aleatoria normal.\n",
    "* Inicialización con los valores por defecto de Keras para una capa Dense (estrategia *glorot uniform*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Inicialización con ceros*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3024 - val_accuracy: 0.1112\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 2.3028 - accuracy: 0.0975 - val_loss: 2.3025 - val_accuracy: 0.1024\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3024 - val_accuracy: 0.1112\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3027 - val_accuracy: 0.0914\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1112\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0994 - val_loss: 2.3028 - val_accuracy: 0.0976\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3028 - val_accuracy: 0.1008\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3025 - val_accuracy: 0.1112\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 2.3027 - accuracy: 0.0991 - val_loss: 2.3027 - val_accuracy: 0.0976\n",
      "313/313 [==============================] - 0s 843us/step - loss: 2.3026 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3026108741760254, 0.10000000149011612]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "\n",
    "    keras.layers.Dense(128,\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=keras.initializers.zeros,\n",
    "    ),\n",
    "\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=10, batch_size=64, callbacks=[callbacks], validation_data=(X_valid, y_valid))\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Si inicializamos los pesos del modelo a cero, cada neurona en la red neuronal tiene la misma salida, lo que significa que todas las neuronas de la capa oculta se comportarán de la misma manera. Como resultado, cada neurona en la capa oculta producirá la misma salida, lo que significa que todas las neuronas de la capa oculta se comportarán de la misma manera. Esto puede provocar que el modelo no aprenda correctamente y que la precisión sea muy baja.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Inicialización con una variable aleatoria normal.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.5196 - accuracy: 0.8186 - val_loss: 0.3827 - val_accuracy: 0.8692\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.3848 - accuracy: 0.8629 - val_loss: 0.3442 - val_accuracy: 0.8792\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8754 - val_loss: 0.3100 - val_accuracy: 0.8932\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.3211 - accuracy: 0.8828 - val_loss: 0.2917 - val_accuracy: 0.8940\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.3016 - accuracy: 0.8894 - val_loss: 0.2837 - val_accuracy: 0.8986\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.2885 - accuracy: 0.8948 - val_loss: 0.2677 - val_accuracy: 0.9006\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2747 - accuracy: 0.8985 - val_loss: 0.2824 - val_accuracy: 0.8960\n",
      "Epoch 8/20\n",
      "933/938 [============================>.] - ETA: 0s - loss: 0.2640 - accuracy: 0.9025\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.2639 - accuracy: 0.9026 - val_loss: 0.2522 - val_accuracy: 0.9058\n",
      "313/313 [==============================] - 0s 820us/step - loss: 0.3526 - accuracy: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35260438919067383, 0.875]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "\n",
    "    keras.layers.Dense(128,\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None),\n",
    "    ),\n",
    "\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=20, batch_size=64, callbacks=[callbacks], validation_data=(X_valid, y_valid))\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La inicialización con variables aleatorias asigna pesos iniciales aleatorios a cada neurona en la red. Esto puede mejorar significativamente el rendimiento del modelo, ya que cada neurona de la red tiene una salida diferente, lo que permite una mayor capacidad de aprendizaje. Además, la inicialización con variables aleatorias se puede ajustar para garantizar que los pesos iniciales sean de magnitud apropiada para el tamaño de la capa.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Inicialización con los valores por defecto de Keras para una capa Dense (estrategia *glorot uniform*)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.5197 - accuracy: 0.8188 - val_loss: 0.4021 - val_accuracy: 0.8592\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3844 - accuracy: 0.8625 - val_loss: 0.3546 - val_accuracy: 0.8734\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3456 - accuracy: 0.8755 - val_loss: 0.3090 - val_accuracy: 0.8930\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3214 - accuracy: 0.8827 - val_loss: 0.3127 - val_accuracy: 0.8832\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.8878 - val_loss: 0.2957 - val_accuracy: 0.8884\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.2901 - accuracy: 0.8929 - val_loss: 0.2668 - val_accuracy: 0.9010\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2769 - accuracy: 0.8991 - val_loss: 0.2940 - val_accuracy: 0.8906\n",
      "Epoch 8/20\n",
      "916/938 [============================>.] - ETA: 0s - loss: 0.2660 - accuracy: 0.9028\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2661 - accuracy: 0.9027 - val_loss: 0.2463 - val_accuracy: 0.9088\n",
      "313/313 [==============================] - 0s 781us/step - loss: 0.3329 - accuracy: 0.8797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3329222500324249, 0.8797000050544739]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "\n",
    "    keras.layers.Dense(128,\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=keras.initializers.glorot_uniform,\n",
    "    ),\n",
    "\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=20, batch_size=64, callbacks=[callbacks], validation_data=(X_valid, y_valid))\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La inicialización por defecto utiliza una estrategia de inicialización específica para cada capa de la red neuronal, como la inicialización de Glorot o la inicialización de He. Estas estrategias de inicialización ajustan automáticamente los pesos iniciales para mejorar el rendimiento del modelo. En general, estas estrategias de inicialización por defecto son más efectivas que la inicialización con variables aleatorias y pueden proporcionar una precisión más alta y una convergencia más rápida.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqIAyVWrTFqV"
   },
   "source": [
    "## 11. Optimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcYj29hYTFqW"
   },
   "source": [
    "**Ejercicio 11 *(0.75 puntos)***: Partiendo de una red similar a la del ejercicio anterior (utilizando la mejor estrategia de inicialización observada), comparar y analizar las diferencias que se observan  al entrenar con varios de los optimizadores vistos en clase, incluyendo SGD como optimizador básico (se puede explorar el espacio de hiperparámetros de cada optimizador, aunque para optimizadores más avanzados del estilo de adam y RMSprop es buena idea dejar los valores por defecto provistos por Keras)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Para este apartado definiré una función con la configuración de las redes neuronales anteriores para ir variando en cada apartado el optimizador*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_optimizers(opt):\n",
    "    model= keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        # keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(len(np.unique(training_labels)), activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer= opt,\n",
    "                metrics =[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(training_images, training_labels, epochs=20, batch_size=32, callbacks=[callbacks], validation_data=(X_valid, y_valid))\n",
    "\n",
    "    return model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizadores = [\"SGD\", \"RMSProp\", \"Adam\", \"AdamW\", \"Adadelta\", \"Adagrad\", \"Adamax\", \"Adafactor\", \"Nadam\", \"Ftrl\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.7460 - accuracy: 0.7505 - val_loss: 0.5024 - val_accuracy: 0.8198\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4821 - accuracy: 0.8298 - val_loss: 0.4231 - val_accuracy: 0.8556\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4347 - accuracy: 0.8466 - val_loss: 0.3897 - val_accuracy: 0.8648\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4053 - accuracy: 0.8551 - val_loss: 0.3774 - val_accuracy: 0.8694\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3838 - accuracy: 0.8626 - val_loss: 0.3542 - val_accuracy: 0.8746\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3669 - accuracy: 0.8686 - val_loss: 0.3478 - val_accuracy: 0.8780\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3540 - accuracy: 0.8730 - val_loss: 0.3305 - val_accuracy: 0.8802\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3404 - accuracy: 0.8764 - val_loss: 0.3383 - val_accuracy: 0.8830\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3311 - accuracy: 0.8807 - val_loss: 0.3019 - val_accuracy: 0.8908\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3211 - accuracy: 0.8841 - val_loss: 0.2952 - val_accuracy: 0.8944\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3129 - accuracy: 0.8860 - val_loss: 0.3112 - val_accuracy: 0.8864\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3043 - accuracy: 0.8887 - val_loss: 0.2768 - val_accuracy: 0.9010\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2977 - accuracy: 0.8915 - val_loss: 0.2733 - val_accuracy: 0.9024\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2915 - accuracy: 0.8930 - val_loss: 0.2733 - val_accuracy: 0.9026\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2848 - accuracy: 0.8967 - val_loss: 0.2778 - val_accuracy: 0.8972\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2792 - accuracy: 0.8985 - val_loss: 0.2734 - val_accuracy: 0.8988\n",
      "Epoch 17/20\n",
      "1856/1875 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.9004\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2729 - accuracy: 0.9004 - val_loss: 0.3008 - val_accuracy: 0.8856\n",
      "313/313 [==============================] - 0s 871us/step - loss: 0.3845 - accuracy: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38446077704429626, 0.8593999743461609]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD = nn_optimizers(tf.keras.optimizers.SGD())\n",
    "SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5007 - accuracy: 0.8182 - val_loss: 0.3496 - val_accuracy: 0.8722\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3859 - accuracy: 0.8603 - val_loss: 0.3506 - val_accuracy: 0.8800\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3668 - accuracy: 0.8710 - val_loss: 0.3261 - val_accuracy: 0.8824\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3571 - accuracy: 0.8748 - val_loss: 0.3131 - val_accuracy: 0.8884\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3553 - accuracy: 0.8792 - val_loss: 0.3288 - val_accuracy: 0.8802\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3532 - accuracy: 0.8780 - val_loss: 0.3951 - val_accuracy: 0.8558\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3499 - accuracy: 0.8796 - val_loss: 0.3554 - val_accuracy: 0.8842\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3472 - accuracy: 0.8813 - val_loss: 0.4687 - val_accuracy: 0.8526\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3446 - accuracy: 0.8841 - val_loss: 0.3829 - val_accuracy: 0.8806\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3417 - accuracy: 0.8823 - val_loss: 0.2967 - val_accuracy: 0.9034\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3406 - accuracy: 0.8874 - val_loss: 0.3087 - val_accuracy: 0.8894\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3366 - accuracy: 0.8877 - val_loss: 0.3292 - val_accuracy: 0.8968\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3375 - accuracy: 0.8872 - val_loss: 0.2885 - val_accuracy: 0.9026\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3390 - accuracy: 0.8883 - val_loss: 0.3163 - val_accuracy: 0.8804\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 2s 855us/step - loss: 0.3311 - accuracy: 0.8898 - val_loss: 0.2763 - val_accuracy: 0.9006\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 2s 837us/step - loss: 0.3378 - accuracy: 0.8899 - val_loss: 0.3011 - val_accuracy: 0.8902\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 2s 841us/step - loss: 0.3387 - accuracy: 0.8905 - val_loss: 0.3092 - val_accuracy: 0.8968\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 2s 826us/step - loss: 0.3353 - accuracy: 0.8911 - val_loss: 0.3213 - val_accuracy: 0.8988\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 2s 847us/step - loss: 0.3353 - accuracy: 0.8912 - val_loss: 0.2961 - val_accuracy: 0.8986\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 2s 840us/step - loss: 0.3324 - accuracy: 0.8930 - val_loss: 0.2927 - val_accuracy: 0.9064\n",
      "313/313 [==============================] - 0s 486us/step - loss: 0.5385 - accuracy: 0.8705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5385109782218933, 0.8705000281333923]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSProp = nn_optimizers(\"rmsprop\")\n",
    "RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 2s 869us/step - loss: 0.4892 - accuracy: 0.8220 - val_loss: 0.3467 - val_accuracy: 0.8742\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 2s 831us/step - loss: 0.3615 - accuracy: 0.8659 - val_loss: 0.3412 - val_accuracy: 0.8774\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 2s 834us/step - loss: 0.3272 - accuracy: 0.8784 - val_loss: 0.3046 - val_accuracy: 0.8856\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 2s 829us/step - loss: 0.3054 - accuracy: 0.8866 - val_loss: 0.2758 - val_accuracy: 0.8964\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 2s 828us/step - loss: 0.2899 - accuracy: 0.8923 - val_loss: 0.2545 - val_accuracy: 0.9088\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 2s 829us/step - loss: 0.2763 - accuracy: 0.8961 - val_loss: 0.2559 - val_accuracy: 0.9036\n",
      "Epoch 7/20\n",
      "1855/1875 [============================>.] - ETA: 0s - loss: 0.2637 - accuracy: 0.9006\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 2s 831us/step - loss: 0.2638 - accuracy: 0.9007 - val_loss: 0.2876 - val_accuracy: 0.8908\n",
      "313/313 [==============================] - 0s 493us/step - loss: 0.3877 - accuracy: 0.8610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3877182602882385, 0.8610000014305115]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adam = nn_optimizers(tf.keras.optimizers.Adam())\n",
    "Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 2s 886us/step - loss: 0.4879 - accuracy: 0.8239 - val_loss: 0.3727 - val_accuracy: 0.8650\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 2s 853us/step - loss: 0.3673 - accuracy: 0.8658 - val_loss: 0.3161 - val_accuracy: 0.8824\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 2s 850us/step - loss: 0.3302 - accuracy: 0.8776 - val_loss: 0.3214 - val_accuracy: 0.8782\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 2s 852us/step - loss: 0.3093 - accuracy: 0.8850 - val_loss: 0.2920 - val_accuracy: 0.8918\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 2s 985us/step - loss: 0.2903 - accuracy: 0.8913 - val_loss: 0.2515 - val_accuracy: 0.9054\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 2s 944us/step - loss: 0.2768 - accuracy: 0.8966 - val_loss: 0.2553 - val_accuracy: 0.9076\n",
      "Epoch 7/20\n",
      "1861/1875 [============================>.] - ETA: 0s - loss: 0.2667 - accuracy: 0.9009\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 2s 955us/step - loss: 0.2668 - accuracy: 0.9009 - val_loss: 0.2403 - val_accuracy: 0.9084\n",
      "313/313 [==============================] - 0s 533us/step - loss: 0.3337 - accuracy: 0.8799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33373570442199707, 0.8798999786376953]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdamW = nn_optimizers(tf.keras.optimizers.AdamW())\n",
    "AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 2s 971us/step - loss: 2.1715 - accuracy: 0.3311 - val_loss: 2.0433 - val_accuracy: 0.4466\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 2s 928us/step - loss: 1.9263 - accuracy: 0.4631 - val_loss: 1.7943 - val_accuracy: 0.4920\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.6901 - accuracy: 0.5132 - val_loss: 1.5670 - val_accuracy: 0.5484\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.4829 - accuracy: 0.5689 - val_loss: 1.3769 - val_accuracy: 0.5986\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.3149 - accuracy: 0.6102 - val_loss: 1.2287 - val_accuracy: 0.6288\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 1.1863 - accuracy: 0.6357 - val_loss: 1.1176 - val_accuracy: 0.6556\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 1.0904 - accuracy: 0.6537 - val_loss: 1.0357 - val_accuracy: 0.6674\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 1.0184 - accuracy: 0.6661 - val_loss: 0.9734 - val_accuracy: 0.6792\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.9635 - accuracy: 0.6771 - val_loss: 0.9253 - val_accuracy: 0.6904\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.9195 - accuracy: 0.6874 - val_loss: 0.8866 - val_accuracy: 0.6984\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.8836 - accuracy: 0.6963 - val_loss: 0.8546 - val_accuracy: 0.7036\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.8537 - accuracy: 0.7044 - val_loss: 0.8274 - val_accuracy: 0.7134\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8281 - accuracy: 0.7122 - val_loss: 0.8043 - val_accuracy: 0.7184\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8059 - accuracy: 0.7195 - val_loss: 0.7839 - val_accuracy: 0.7246\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7864 - accuracy: 0.7258 - val_loss: 0.7658 - val_accuracy: 0.7324\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7694 - accuracy: 0.7318 - val_loss: 0.7499 - val_accuracy: 0.7376\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7541 - accuracy: 0.7363 - val_loss: 0.7356 - val_accuracy: 0.7426\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7403 - accuracy: 0.7418 - val_loss: 0.7227 - val_accuracy: 0.7466\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.7276 - accuracy: 0.7463 - val_loss: 0.7109 - val_accuracy: 0.7532\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 2s 910us/step - loss: 0.7160 - accuracy: 0.7516 - val_loss: 0.7000 - val_accuracy: 0.7584\n",
      "313/313 [==============================] - 0s 492us/step - loss: 0.7274 - accuracy: 0.7406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7274273633956909, 0.7405999898910522]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adadelta = nn_optimizers(tf.keras.optimizers.Adadelta())\n",
    "Adadelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 2s 834us/step - loss: 1.1466 - accuracy: 0.6387 - val_loss: 0.7331 - val_accuracy: 0.7606\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 1s 790us/step - loss: 0.6700 - accuracy: 0.7736 - val_loss: 0.6007 - val_accuracy: 0.8026\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 1s 784us/step - loss: 0.5846 - accuracy: 0.8040 - val_loss: 0.5465 - val_accuracy: 0.8196\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.5424 - accuracy: 0.8168 - val_loss: 0.5142 - val_accuracy: 0.8272\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 1s 789us/step - loss: 0.5169 - accuracy: 0.8239 - val_loss: 0.4936 - val_accuracy: 0.8372\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 1s 787us/step - loss: 0.4987 - accuracy: 0.8296 - val_loss: 0.4772 - val_accuracy: 0.8426\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 1s 792us/step - loss: 0.4848 - accuracy: 0.8338 - val_loss: 0.4642 - val_accuracy: 0.8452\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 2s 847us/step - loss: 0.4740 - accuracy: 0.8368 - val_loss: 0.4536 - val_accuracy: 0.8466\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 2s 819us/step - loss: 0.4645 - accuracy: 0.8397 - val_loss: 0.4484 - val_accuracy: 0.8480\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 1s 791us/step - loss: 0.4568 - accuracy: 0.8425 - val_loss: 0.4386 - val_accuracy: 0.8518\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 2s 802us/step - loss: 0.4499 - accuracy: 0.8444 - val_loss: 0.4333 - val_accuracy: 0.8544\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 2s 819us/step - loss: 0.4439 - accuracy: 0.8461 - val_loss: 0.4274 - val_accuracy: 0.8552\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 2s 860us/step - loss: 0.4385 - accuracy: 0.8478 - val_loss: 0.4228 - val_accuracy: 0.8560\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 2s 818us/step - loss: 0.4339 - accuracy: 0.8496 - val_loss: 0.4187 - val_accuracy: 0.8562\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 2s 813us/step - loss: 0.4295 - accuracy: 0.8511 - val_loss: 0.4153 - val_accuracy: 0.8572\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 2s 808us/step - loss: 0.4255 - accuracy: 0.8526 - val_loss: 0.4110 - val_accuracy: 0.8598\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 2s 802us/step - loss: 0.4219 - accuracy: 0.8533 - val_loss: 0.4070 - val_accuracy: 0.8594\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 1s 783us/step - loss: 0.4185 - accuracy: 0.8544 - val_loss: 0.4037 - val_accuracy: 0.8588\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.4152 - accuracy: 0.8559 - val_loss: 0.4022 - val_accuracy: 0.8614\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 1s 782us/step - loss: 0.4121 - accuracy: 0.8572 - val_loss: 0.3983 - val_accuracy: 0.8620\n",
      "313/313 [==============================] - 0s 559us/step - loss: 0.4437 - accuracy: 0.8443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44365063309669495, 0.8442999720573425]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adagrad = nn_optimizers(tf.keras.optimizers.Adagrad())\n",
    "Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.5331 - accuracy: 0.8140 - val_loss: 0.3871 - val_accuracy: 0.8668\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3959 - accuracy: 0.8585 - val_loss: 0.3414 - val_accuracy: 0.8770\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3553 - accuracy: 0.8714 - val_loss: 0.3182 - val_accuracy: 0.8888\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3282 - accuracy: 0.8800 - val_loss: 0.3081 - val_accuracy: 0.8890\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3082 - accuracy: 0.8865 - val_loss: 0.2843 - val_accuracy: 0.8964\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2935 - accuracy: 0.8921 - val_loss: 0.2649 - val_accuracy: 0.9062\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2796 - accuracy: 0.8968 - val_loss: 0.2626 - val_accuracy: 0.9022\n",
      "Epoch 8/20\n",
      "1837/1875 [============================>.] - ETA: 0s - loss: 0.2686 - accuracy: 0.9009\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2687 - accuracy: 0.9009 - val_loss: 0.2415 - val_accuracy: 0.9126\n",
      "313/313 [==============================] - 0s 825us/step - loss: 0.3310 - accuracy: 0.8810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33104655146598816, 0.8809999823570251]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adamax = nn_optimizers(tf.keras.optimizers.Adamax())\n",
    "Adamax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adafactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.0914\n",
      "313/313 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.10000000149011612]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adafactor = nn_optimizers(tf.keras.optimizers.Adafactor())\n",
    "Adafactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4727 - accuracy: 0.8311 - val_loss: 0.3836 - val_accuracy: 0.8584\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3606 - accuracy: 0.8684 - val_loss: 0.3180 - val_accuracy: 0.8796\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3242 - accuracy: 0.8799 - val_loss: 0.3063 - val_accuracy: 0.8868\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3028 - accuracy: 0.8873 - val_loss: 0.2780 - val_accuracy: 0.8960\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2862 - accuracy: 0.8935 - val_loss: 0.2455 - val_accuracy: 0.9078\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2718 - accuracy: 0.8990 - val_loss: 0.2570 - val_accuracy: 0.9026\n",
      "Epoch 7/20\n",
      "1860/1875 [============================>.] - ETA: 0s - loss: 0.2615 - accuracy: 0.9019\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2615 - accuracy: 0.9020 - val_loss: 0.2306 - val_accuracy: 0.9124\n",
      "313/313 [==============================] - 0s 821us/step - loss: 0.3265 - accuracy: 0.8831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3264775276184082, 0.8830999732017517]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nadam = nn_optimizers(tf.keras.optimizers.Nadam())\n",
    "Nadam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ftrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 2.3026 - accuracy: 0.0974 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "313/313 [==============================] - 0s 777us/step - loss: 2.3026 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3025848865509033, 0.10000000149011612]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ftrl = nn_optimizers(tf.keras.optimizers.Ftrl())\n",
    "Ftrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Resumen de los resultados de los optimizadores*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión del modelo con el optimizador SGD es: 0.8593999743461609 \n",
      "La precisión del modelo con el optimizador RMSProp es: 0.8705000281333923 \n",
      "La precisión del modelo con el optimizador Adam es: 0.8610000014305115 \n",
      "La precisión del modelo con el optimizador AdamW es: 0.8798999786376953 \n",
      "La precisión del modelo con el optimizador Adadelta es: 0.7405999898910522 \n",
      "La precisión del modelo con el optimizador Adagrad es: 0.8442999720573425 \n",
      "La precisión del modelo con el optimizador Adamax es: 0.8809999823570251 \n",
      "La precisión del modelo con el optimizador Adafactor es: 0.10000000149011612 \n",
      "La precisión del modelo con el optimizador Nadam es: 0.8830999732017517 \n",
      "La precisión del modelo con el optimizador Ftrl es: 0.10000000149011612 \n",
      "--------------------------------------------------------------------------\n",
      "El mejor optimizador ha resultado ser Nadam con un accuracy de: 0.8830999732017517\n"
     ]
    }
   ],
   "source": [
    "diccionario_optimizadores = {\n",
    "    \"SGD\": SGD[1],\n",
    "    \"RMSProp\": RMSProp[1],\n",
    "    \"Adam\": Adam[1],\n",
    "    \"AdamW\": AdamW[1],  \n",
    "    \"Adadelta\": Adadelta[1],\n",
    "    \"Adagrad\" : Adagrad[1],\n",
    "    \"Adamax\": Adamax[1],\n",
    "    \"Adafactor\": Adafactor[1],\n",
    "    \"Nadam\": Nadam[1],\n",
    "    \"Ftrl\": Ftrl[1]\n",
    "}\n",
    "best_optimizer = 0\n",
    "best_optimizer_tag = 0\n",
    "for i, j in diccionario_optimizadores.items():\n",
    "    print(\"La precisión del modelo con el optimizador {} es: {} \".format(i, j))\n",
    "    if best_optimizer < j:\n",
    "        best_optimizer = j\n",
    "        best_optimizer_tag = i\n",
    "\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(\"El mejor optimizador ha resultado ser {} con un accuracy de: {}\".format(best_optimizer_tag, best_optimizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkfTFoJOTFqZ"
   },
   "source": [
    "## 12. Regularización y red final "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6CQhK7ZTFqZ"
   },
   "source": [
    "**Ejercicio 12 *(1 punto)***: Entrenar una red final que sea capaz de obtener una accuracy en el validation set cercana al 90%. Para ello, combinar todo lo aprendido anteriormente y utilizar técnicas de regularización para evitar overfitting. Algunos de los elementos que pueden tenerse en cuenta son los siguientes.\n",
    "\n",
    "* Número de capas y neuronas por capa\n",
    "* Optimizadores y sus parámetros\n",
    "* Batch size\n",
    "* Unidades de activación\n",
    "* Uso de capas dropout, regularización L2, regularización L1...\n",
    "* Early stopping (se puede aplicar como un callback de Keras, o se puede ver un poco \"a ojo\" cuándo el modelo empieza a caer en overfitting y seleccionar el número de epochs necesarias)\n",
    "* Batch normalization\n",
    "\n",
    "Si los modelos entrenados anteriormente ya se acercaban al valor requerido de accuracy, probar distintas estrategias igualmente y comentar los resultados.\n",
    "\n",
    "Explicar brevemente la estrategia seguida y los modelos probados para obtener el modelo final, que debe verse entrenado en este Notebook. No es necesario guardar el entrenamiento de todos los modelos que se han probado, es suficiente con explicar cómo se ha llegado al modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_resultado = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "AUJ5AtunTFqa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4703 - accuracy: 0.8309 - val_loss: 0.3472 - val_accuracy: 0.8720\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3560 - accuracy: 0.8700 - val_loss: 0.3178 - val_accuracy: 0.8786\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3236 - accuracy: 0.8799 - val_loss: 0.2792 - val_accuracy: 0.8958\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3036 - accuracy: 0.8878 - val_loss: 0.2992 - val_accuracy: 0.8930\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2883 - accuracy: 0.8936 - val_loss: 0.2597 - val_accuracy: 0.9022\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2735 - accuracy: 0.8968 - val_loss: 0.2410 - val_accuracy: 0.9076\n",
      "Epoch 7/30\n",
      "1832/1875 [============================>.] - ETA: 0s - loss: 0.2617 - accuracy: 0.9020\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2620 - accuracy: 0.9020 - val_loss: 0.2493 - val_accuracy: 0.9074\n",
      "313/313 [==============================] - 0s 530us/step - loss: 0.3552 - accuracy: 0.8718\n",
      "\n",
      "\n",
      "Mejor resultado de accuracy obtenido: 0.8718000054359436\n",
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4713 - accuracy: 0.8293 - val_loss: 0.3545 - val_accuracy: 0.8702\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3577 - accuracy: 0.8690 - val_loss: 0.3169 - val_accuracy: 0.8880\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 2s 984us/step - loss: 0.3272 - accuracy: 0.8789 - val_loss: 0.3023 - val_accuracy: 0.8870\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 2s 988us/step - loss: 0.3060 - accuracy: 0.8868 - val_loss: 0.2832 - val_accuracy: 0.8938\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 2s 986us/step - loss: 0.2863 - accuracy: 0.8929 - val_loss: 0.2583 - val_accuracy: 0.9022\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 2s 982us/step - loss: 0.2719 - accuracy: 0.8976 - val_loss: 0.2418 - val_accuracy: 0.9078\n",
      "Epoch 7/30\n",
      "1869/1875 [============================>.] - ETA: 0s - loss: 0.2609 - accuracy: 0.9015\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 2s 988us/step - loss: 0.2613 - accuracy: 0.9014 - val_loss: 0.2285 - val_accuracy: 0.9108\n",
      "313/313 [==============================] - 0s 520us/step - loss: 0.3199 - accuracy: 0.8815\n",
      "\n",
      "\n",
      "Mejor resultado de accuracy obtenido: 0.8815000057220459\n",
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4718 - accuracy: 0.8313 - val_loss: 0.3648 - val_accuracy: 0.8706\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 2s 979us/step - loss: 0.3606 - accuracy: 0.8684 - val_loss: 0.3056 - val_accuracy: 0.8892\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 2s 976us/step - loss: 0.3261 - accuracy: 0.8781 - val_loss: 0.3301 - val_accuracy: 0.8812\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 2s 978us/step - loss: 0.3048 - accuracy: 0.8862 - val_loss: 0.2934 - val_accuracy: 0.8888\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 2s 974us/step - loss: 0.2886 - accuracy: 0.8924 - val_loss: 0.2652 - val_accuracy: 0.8982\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 2s 976us/step - loss: 0.2729 - accuracy: 0.8985 - val_loss: 0.2693 - val_accuracy: 0.9004\n",
      "Epoch 7/30\n",
      "1828/1875 [============================>.] - ETA: 0s - loss: 0.2641 - accuracy: 0.9001\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 2s 981us/step - loss: 0.2638 - accuracy: 0.9001 - val_loss: 0.2452 - val_accuracy: 0.9054\n",
      "313/313 [==============================] - 0s 529us/step - loss: 0.3466 - accuracy: 0.8792\n",
      "\n",
      "\n",
      "Mejor resultado de accuracy obtenido: 0.8815000057220459\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    # keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer= best_optimizer_tag,\n",
    "                metrics =[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(training_images, training_labels, epochs=30, batch_size=32, callbacks=[callbacks], validation_data=(X_valid, y_valid))\n",
    "\n",
    "    resultado = model.evaluate(test_images, test_labels)\n",
    "\n",
    "\n",
    "    if mejor_resultado < resultado[1]:\n",
    "        mejor_resultado = resultado[1]\n",
    "    print(\"\\n\")\n",
    "    print(\"Mejor resultado de accuracy obtenido: {}\".format(mejor_resultado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FIN DEL CUADERNO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
