{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiDzBoKGwmMZ"
   },
   "source": [
    "# REDES NEURONALES\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeO2xVqBv1fx"
   },
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhzeF2BVvvi7"
   },
   "source": [
    "\n",
    "\n",
    "En esta actividad vamos a utilizar una red neuronal para clasificar imágenes de prendas de ropa. Para ello, utilizaremos Keras con TensorFlow.\n",
    "\n",
    "El dataset a utilizar es Fashion MNIST, un problema sencillo con imágenes pequeñas de ropa, pero más interesante que el dataset de MNIST. Puedes consultar más información sobre el dataset en [este enlace](https://github.com/zalandoresearch/fashion-mnist).\n",
    "\n",
    "El código utilizado para contestar tiene que quedar claramente reflejado en el Notebook. Puedes crear nuevas celdas si así lo deseas para estructurar tu código y sus salidas. A la hora de entregar el notebook, **asegúrate de que los resultados de ejecutar tu código han quedado guardados**. Por ejemplo, a la hora de entrenar una red neuronal tiene que verse claramente un log de los resultados de cada epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gSHr268SwmMa"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zScMKU2OKSPD"
   },
   "source": [
    "En primer lugar vamos a importar el dataset Fashion MNIST (recordad que este es uno de los dataset de entranamiento que estan guardados en keras) que es el que vamos a utilizar en esta actividad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4voG2hxxG4h3"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JphLsCvgKrzb"
   },
   "source": [
    "Llamar a **load_data** en este dataset nos dará dos conjuntos de dos listas, estos serán los valores de entrenamiento y prueba para los gráficos que contienen las prendas de vestir y sus etiquetas.\n",
    "\n",
    "Nota: Aunque en esta actividad lo veis de esta forma, también lo vais a poder encontrar como 4 variables de esta forma: training_images, training_labels, test_images, test_labels = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1muD4PHEG4h6",
    "outputId": "2f6beb46-3176-4adf-a64b-6dab9ea81bbe"
   },
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWGpJqVVLT3Y"
   },
   "source": [
    "Antes de continuar vamos a dar un vistazo a nuestro dataset, para ello vamos a ver una imagen de entrenamiento y su etiqueta o clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "id": "t5a5PlswG4h8",
    "outputId": "2edeb68d-fcba-4f20-c49a-f80a5c51b012"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3a76d1aa40>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Label: {}\".format(training_labels[0]))\n",
    "plt.imshow(training_images[0], cmap=\"gray\") # recordad que siempre es preferible trabajar en blanco y negro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCJvZx3MLucY"
   },
   "source": [
    "Habréis notado que todos los valores numericos están entre 0 y 255. Si estamos entrenando una red neuronal, una buena practica es transformar todos los valores entre 0 y 1, un proceso llamado \"normalización\" y afortunadamente en Python es fácil normalizar una lista. Lo puedes hacer de esta manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tojL1BmjG4h_"
   },
   "outputs": [],
   "source": [
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaqXlSMBwmMg"
   },
   "source": [
    "## 1. Información sobre el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0aer8ZZwmMh"
   },
   "source": [
    "Una vez tenemos los datos cargados en memoria, vamos a obtener información sobre los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-im9PnEwmMh"
   },
   "source": [
    "**Pregunta 1.1 *(0.25 puntos)*** ¿Cuántas imágenes hay de *training* y de *test*? ¿Qué tamaño tienen las imágenes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lvP0Y4SCwmMi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images of the train set: 60000\n",
      "Number of images of the test set: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images of the train set: {}\".format(len(training_images)))\n",
    "print(\"Number of images of the test set: {}\".format(len(test_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay un total de 60000 imágenes en el set de entrenamiento y 10000 en el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_images[0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xwp5ljFKwmMj"
   },
   "source": [
    "*Podemos observar que las imágenes con las que estamos trabajando tienen dimensiones de 28x28 píxeles, con una totalidad de 784 píxeles por imagen*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2LsvfHOwmMk"
   },
   "source": [
    "**Pregunta 1.2 *(0.25 puntos)*** Realizar una exploración de las variables que contienen los datos. Describir en qué consiste un example del dataset (qué información se guarda en cada imagen) y describir qué contiene la información en y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3W5rzaGxwmMk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "class_names[training_labels[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaEWKFyvwmMm"
   },
   "source": [
    "*En las etiquetas del conjunto de datos, tanto de entrenamiento como de test, podemos ver qué tipo de prenda contiene cada imagen*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI3IAhOQ8zHi"
   },
   "source": [
    "## 2. Creación del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYUWWsszMAKt"
   },
   "source": [
    "Ahora vamos a definir el modelo, pero antes vamos a repasar algunos comandos y conceptos muy útiles:\n",
    "* **Sequential**: Eso define una SECUENCIA de capas en la red neuronal\n",
    "* **Dense**: Añade una capa de neuronas\n",
    "* **Flatten**: ¿Recuerdas cómo eran las imágenes cuando las imprimiste para poder verlas? Un cuadrado, Flatten toma ese cuadrado y lo convierte en un vector de una dimensión.\n",
    "\n",
    "Cada capa de neuronas necesita una función de activación. Normalmente se usa la función relu en las capas intermedias y softmax en la ultima capa (en problemas de clasificación de más de dos items)\n",
    "* **Relu** significa que \"Si X>0 devuelve X, si no, devuelve 0\", así que lo que hace es pasar sólo valores 0 o mayores a la siguiente capa de la red.\n",
    "* **Softmax** toma un conjunto de valores, y escoge el más grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgBW1yE2MwPp"
   },
   "source": [
    " **Pregunta 2.1 (2 puntos)**. Utilizando Keras, y preparando los datos de X e y como fuera necesario, define y entrena una red neuronal que sea capaz de clasificar imágenes de Fashion MNIST con las siguientes características:\n",
    "\n",
    "* Una hidden layer de tamaño 128, utilizando unidades sigmoid\n",
    "Optimizador Adam.\n",
    "* Durante el entrenamiento, la red tiene que mostrar resultados de loss y accuracy por cada epoch.\n",
    "* La red debe entrenar durante 10 epochs y batch size de 64.\n",
    "* La última capa debe de ser una capa softmax.\n",
    "* Tu red tendría que ser capaz de superar fácilmente 80% de accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizamos los datos de validación para mejorar el accuracy del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = training_images[:5000], training_images[5000:]\n",
    "y_valid, y_train = training_labels[:5000], training_labels[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Diseñamos la red neuronal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "aTaD2QXIORwu"
   },
   "outputs": [],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Compilamos el modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Entrenando y evaluando el modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.5195 - accuracy: 0.8188 - val_loss: 0.4038 - val_accuracy: 0.8598\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3873 - accuracy: 0.8628 - val_loss: 0.3482 - val_accuracy: 0.8780\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3498 - accuracy: 0.8747 - val_loss: 0.3227 - val_accuracy: 0.8804\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3209 - accuracy: 0.8842 - val_loss: 0.3025 - val_accuracy: 0.8892\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3033 - accuracy: 0.8893 - val_loss: 0.2990 - val_accuracy: 0.8910\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2868 - accuracy: 0.8955 - val_loss: 0.2601 - val_accuracy: 0.9058\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2764 - accuracy: 0.8990 - val_loss: 0.2512 - val_accuracy: 0.9044\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2628 - accuracy: 0.9028 - val_loss: 0.2492 - val_accuracy: 0.9100\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2556 - accuracy: 0.9053 - val_loss: 0.2259 - val_accuracy: 0.9164\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 0.2455 - accuracy: 0.9086 - val_loss: 0.2265 - val_accuracy: 0.9142\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_images, training_labels, epochs=10, batch_size=64, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bxr5hTKYOQnK"
   },
   "source": [
    "Para concluir el entrenamiento de la red neuronal, una buena práctica es evaluar el modelo para ver si la precisión de entrenamiento es real\n",
    "\n",
    "**pregunta 2.2 (0.5 puntos)**: Evalúa el modelo con las imágenes y etiquetas test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.8821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3296174108982086, 0.882099986076355]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygMVnmSYO83U"
   },
   "source": [
    "\n",
    "## 3: Funcionamiento de las predicción de la red neuronal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMa-GR0Kvcqh"
   },
   "source": [
    "Ahora vamos a explorar el código con una serie de ejercicios para alcanzar un grado de comprensión mayor sobre las redes neuronales y su entrenamiento.\n",
    "\n",
    "Sigue los siguientes pasos: \n",
    "\n",
    "* Crea una variable llamada **classifications** para construir un clasificador con las imágenes de prueba, para ello puedes utilizar la función predict sobre el conjunto de test\n",
    "* Imprime con la función print la primera entrada en las clasificaciones. \n",
    "\n",
    "**pregunta 3.1 (0.25 puntos)**, el resultado al imprimirlo es un vector de números, \n",
    "* ¿Por qué crees que ocurre esto? ¿Qué representa este vector de números?\n",
    "\n",
    "**pregunta 3.2 (0.25 puntos)**\n",
    "* ¿Cúal es la clase de la primera entrada de la variable **classifications**? La respuesta puede ser un número o su etiqueta/clase equivalente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "classificatios = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "b-mL-h4xQhCm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5880979e-06, 1.9694619e-08, 9.5957731e-09, 3.8337746e-09, 2.0701178e-07, 3.1987298e-03, 3.2653249e-06, 2.3212885e-02, 1.9574305e-05, 9.7356266e-01], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificatios[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvbVC9gaQhMY"
   },
   "source": [
    "Tu respuesta a la pregunta 3.1 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La función .predict() de keras aplicada al conjunto de test nos proporciona un array de con las probabilidades de que se trate de una categoría u otra. En este caso podemos observar como la etiqueta más probable es efectivamente la de la etiqueta número 9, \"ankle boot\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRWo-75tdgv0"
   },
   "source": [
    "Tu respuesta a la pregunta 3.2 aquí:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay que tener en cuenta que esta función está pensada para las predicciones del modelo\n",
    "def clase_mas_probable(i):\n",
    "    if i >= 0 and i < 10:\n",
    "        print(\"La clase más probable para la imagen número {} es {} con la etiqueta número {}\".format(i + 1, class_names[list(classificatios[i]).index(max(classificatios[i]))], list(classificatios[i]).index(max(classificatios[i]))))\n",
    "        plt.imshow(training_images[i], cmap=\"gray\")\n",
    "    else:\n",
    "        print(\"Not in the wardrobe\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clase más probable para la imagen número 1 es Ankle boot con la etiqueta número 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clase_mas_probable(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[test_labels[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiQ8qAzhRQ4L"
   },
   "source": [
    "## 4: Impacto variar el número de neuronas en las capas ocultas\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lsqive4ivMF9"
   },
   "source": [
    "En este ejercicio vamos a experimentar con nuestra red neuronal cambiando el numero de neuronas por 512 y por 1024. Para ello, utiliza la red neuronal de la pregunta 1, y en su capa oculta cambia las 128 neuronas por:\n",
    "\n",
    "* **512 neuronas en la capa oculta\n",
    "* **1024 neuronas en la capa oculta\n",
    "\n",
    "Entrena la red en ambos casos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 512 Neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "cdP8ZwuaUV93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.4845 - accuracy: 0.8289 - val_loss: 0.3504 - val_accuracy: 0.8778\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.3616 - accuracy: 0.8692 - val_loss: 0.3164 - val_accuracy: 0.8818\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.3208 - accuracy: 0.8821 - val_loss: 0.2967 - val_accuracy: 0.8900\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.2974 - accuracy: 0.8897 - val_loss: 0.2540 - val_accuracy: 0.9054\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.2811 - accuracy: 0.8973 - val_loss: 0.2579 - val_accuracy: 0.9040\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.2641 - accuracy: 0.9027 - val_loss: 0.2432 - val_accuracy: 0.9084\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.2523 - accuracy: 0.9071 - val_loss: 0.2373 - val_accuracy: 0.9102\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.2402 - accuracy: 0.9102 - val_loss: 0.2157 - val_accuracy: 0.9164\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.2286 - accuracy: 0.9141 - val_loss: 0.2302 - val_accuracy: 0.9134\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.2189 - accuracy: 0.9188 - val_loss: 0.2299 - val_accuracy: 0.9120\n"
     ]
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(512, activation=\"relu\"),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=10, batch_size=64, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3565 - accuracy: 0.8774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3564845025539398, 0.8773999810218811]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "classificatios = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clase más probable para la imagen número 1 es Ankle boot con la etiqueta número 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clase_mas_probable(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1024 Neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.4741 - accuracy: 0.8316 - val_loss: 0.3407 - val_accuracy: 0.8784\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.3579 - accuracy: 0.8697 - val_loss: 0.3205 - val_accuracy: 0.8836\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.3219 - accuracy: 0.8816 - val_loss: 0.2759 - val_accuracy: 0.8968\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.2951 - accuracy: 0.8898 - val_loss: 0.2775 - val_accuracy: 0.8976\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.2793 - accuracy: 0.8960 - val_loss: 0.2629 - val_accuracy: 0.8970\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.2608 - accuracy: 0.9027 - val_loss: 0.2310 - val_accuracy: 0.9112\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.2509 - accuracy: 0.9065 - val_loss: 0.2301 - val_accuracy: 0.9146\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.2384 - accuracy: 0.9102 - val_loss: 0.2210 - val_accuracy: 0.9168\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.2248 - accuracy: 0.9160 - val_loss: 0.2031 - val_accuracy: 0.9228\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.2182 - accuracy: 0.9187 - val_loss: 0.2068 - val_accuracy: 0.9216\n"
     ]
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(1024, activation=\"relu\"),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=10, batch_size=64, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3277 - accuracy: 0.8862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32770323753356934, 0.8862000107765198]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "classificatios = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wG0h2HL-Uj93"
   },
   "source": [
    "**pregunta 4.1 (0.5 puntos)**: ¿Cuál es el impacto que tiene la red neuronal? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkZYq4xBvnrS"
   },
   "source": [
    "*Podemos observar una ínfima mejora en el modelo y un tiempo de ejecución superior, pasando de tardar 39 segundos a casi 60. No merece la pena aumentar el número de neuronas dentro de la misma capa para este problema en concreto.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora entrenais el modelo de esta forma (con 512 y 1024 neuronas en la capa oculta) y volveis a ejecutar el predictor guardado en la variable **classifications**, escribir el código del clasificador del ejercicio 1 de nuevo e imprimid el primer objeto guardado en la variable classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "RdJHl3V-G4iS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clase más probable para la imagen número 1 es Ankle boot con la etiqueta número 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clase_mas_probable(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-NpUI9EVkVz"
   },
   "source": [
    "\n",
    "**pregunta 4.2 (0.25 puntos)**: \n",
    "\n",
    "* ¿En qué clase está clasificado ahora la primera prenda de vestir de la variable classifications?\n",
    "\n",
    "**pregunta 4.3 (0.25 puntos)**: \n",
    "\n",
    "* ¿Por qué crees que ha ocurrido esto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3NfwdOGZcAa"
   },
   "source": [
    "Tu respuesta a la pregunta 4.2 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La primera prenda de vestir la clasifica correctamente como un Ankle boot*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFmfpxE1ZcJx"
   },
   "source": [
    "Tu respuesta a la pregunta 4.3 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tanto con 512 como 1024 neuronas en la capa oculta podemos ver que el modelo predice que la primera imagen del set de test es un Ankle boot. Esto es así porque con la cantidad y sencillez de los datos con los que estamos trabajando, aumentar el número de nueronas de la capa oculta no mejora practicamente nada el resultado del modelo*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59eM76O1YekZ"
   },
   "source": [
    "## 5: Capa Flatten\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6LGnSxBu-ww"
   },
   "source": [
    "En este ejercicio vamos a ver que ocurre cuando quitamos la capa flatten, para ello, escribe la red neuronal de la pregunta 1 y no pongas la capa Flatten.\n",
    "\n",
    "**pregunta 5 (0.5 puntos):** ¿Puedes explicar a qué se debe el error que da?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ecfEVKEuG4iU"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m      2\u001b[0m     \u001b[39m# keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m128\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      4\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(training_labels)), activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m ])\n\u001b[1;32m      7\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m             optimizer\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m             metrics \u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(training_images, training_labels, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, validation_data\u001b[39m=\u001b[39m(X_valid, y_valid))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    # keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=10, batch_size=64, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aNmrkkOZN6D"
   },
   "source": [
    "Tu respuesta a la pregunta 5 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*El modelo fracasa en entrenar con los datos porque la capa de entrada no es unidimensional. Necesitamos .Flatten() para convertir los píxeles de la imagen, que consta de una matriz bidimiensional de 28x28, en otra matriz unidimensional de 784x1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f37cIr81ZYJj"
   },
   "source": [
    "## 6: Número de neuronas de la capa de salida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zk1xYVAQu0wN"
   },
   "source": [
    "Considerad la capa final, la de salida de la red neuronal de la pregunta 1.\n",
    "\n",
    "**pregunta 6.1 (0.25 puntos)**: ¿Por qué son 10 las neuronas de la última capa?\n",
    "\n",
    "**pregunta 6.2 (0.25 puntos)**: ¿Qué pasaría si tuvieras una cantidad diferente a 10? \n",
    "\n",
    "Por ejemplo, intenta entrenar la red con 5, para ello utiliza la red neuronal de la pregunta 1 y cambia a 5 el número de neuronas en la última capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FhbZkppYZOCS"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m      2\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mFlatten(input_shape\u001b[39m=\u001b[39m[\u001b[39mlen\u001b[39m(training_images[\u001b[39m0\u001b[39m]), \u001b[39mlen\u001b[39m(training_images[\u001b[39m1\u001b[39m])]),\n\u001b[1;32m      3\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m128\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      4\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m5\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m ])\n\u001b[1;32m      7\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m             optimizer\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m             metrics \u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(training_images, training_labels, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, validation_data\u001b[39m=\u001b[39m(X_valid, y_valid))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=10, batch_size=64, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLsQcq-6aUoD"
   },
   "source": [
    "Tu respuestas a la pregunta 6.1 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*En la capa de salida necesitamos tantas neuronas como clases vayamos a predecir. Por eso al haber 10 clases necesitaremos 10 neuronas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1f_7ZFeaUu6"
   },
   "source": [
    "Tu respuestas a la pregunta 6.2 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Al tener un número de neuronas diferente al número de clases, el modelo simplemente sería incapaz de entrenar y aprender*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNIBCkshaf2y"
   },
   "source": [
    "## 7: Aumento de epoch y su efecto en la red neuronal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg8tTqYPuwGc"
   },
   "source": [
    "En este ejercicio vamos a ver el impacto de aumentar los epoch en el entrenamiento. Usando la red neuronal de la pregunta 1:\n",
    "\n",
    "**pregunta 7.1 (0.15 puntos)**\n",
    "* Intentad 15 epoch para su entrenamiento, probablemente obtendras un modelo con una pérdida mucho mejor que el que tiene 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Cb5vk_imG4iZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "938/938 [==============================] - 4s 3ms/step - loss: 0.5183 - accuracy: 0.8198 - val_loss: 0.3875 - val_accuracy: 0.8712\n",
      "Epoch 2/15\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3853 - accuracy: 0.8633 - val_loss: 0.3548 - val_accuracy: 0.8704\n",
      "Epoch 3/15\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3461 - accuracy: 0.8755 - val_loss: 0.3205 - val_accuracy: 0.8832\n",
      "Epoch 4/15\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3217 - accuracy: 0.8840 - val_loss: 0.2836 - val_accuracy: 0.8954\n",
      "Epoch 5/15\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3037 - accuracy: 0.8888 - val_loss: 0.2696 - val_accuracy: 0.9014\n",
      "Epoch 6/15\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2882 - accuracy: 0.8949 - val_loss: 0.2628 - val_accuracy: 0.9052\n",
      "Epoch 7/15\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2737 - accuracy: 0.8989 - val_loss: 0.2361 - val_accuracy: 0.9156\n",
      "Epoch 8/15\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2633 - accuracy: 0.9021 - val_loss: 0.2465 - val_accuracy: 0.9128\n",
      "Epoch 9/15\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2546 - accuracy: 0.9061 - val_loss: 0.2279 - val_accuracy: 0.9120\n",
      "Epoch 10/15\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2451 - accuracy: 0.9095 - val_loss: 0.2294 - val_accuracy: 0.9138\n",
      "Epoch 11/15\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2360 - accuracy: 0.9117 - val_loss: 0.2095 - val_accuracy: 0.9204\n",
      "Epoch 12/15\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2282 - accuracy: 0.9153 - val_loss: 0.2062 - val_accuracy: 0.9210\n",
      "Epoch 13/15\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2207 - accuracy: 0.9189 - val_loss: 0.1966 - val_accuracy: 0.9270\n",
      "Epoch 14/15\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2156 - accuracy: 0.9197 - val_loss: 0.1888 - val_accuracy: 0.9276\n",
      "Epoch 15/15\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2101 - accuracy: 0.9213 - val_loss: 0.1910 - val_accuracy: 0.9290\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34068775177001953, 0.8834999799728394]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=15, batch_size=64, validation_data=(X_valid, y_valid))\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pregunta 7.2 (0.15 puntos)**\n",
    "* Intenta ahora con 30 epoch para su entrenamiento, podrás ver que el valor de la pérdida deja de disminuir, y a veces aumenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "I9jQ26Gda5cv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 4s 3ms/step - loss: 0.5232 - accuracy: 0.8187 - val_loss: 0.4031 - val_accuracy: 0.8638\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3937 - accuracy: 0.8603 - val_loss: 0.3343 - val_accuracy: 0.8834\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3521 - accuracy: 0.8724 - val_loss: 0.3180 - val_accuracy: 0.8860\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3257 - accuracy: 0.8824 - val_loss: 0.3032 - val_accuracy: 0.8866\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3068 - accuracy: 0.8881 - val_loss: 0.2729 - val_accuracy: 0.9008\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2929 - accuracy: 0.8935 - val_loss: 0.2593 - val_accuracy: 0.9038\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2802 - accuracy: 0.8975 - val_loss: 0.2524 - val_accuracy: 0.9094\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2689 - accuracy: 0.9004 - val_loss: 0.2546 - val_accuracy: 0.9054\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2589 - accuracy: 0.9044 - val_loss: 0.2536 - val_accuracy: 0.9028\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2499 - accuracy: 0.9079 - val_loss: 0.2308 - val_accuracy: 0.9134\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2422 - accuracy: 0.9099 - val_loss: 0.2389 - val_accuracy: 0.9108\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2343 - accuracy: 0.9132 - val_loss: 0.2171 - val_accuracy: 0.9190\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2284 - accuracy: 0.9163 - val_loss: 0.2146 - val_accuracy: 0.9218\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2193 - accuracy: 0.9190 - val_loss: 0.2008 - val_accuracy: 0.9256\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2140 - accuracy: 0.9201 - val_loss: 0.1988 - val_accuracy: 0.9226\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2084 - accuracy: 0.9225 - val_loss: 0.1955 - val_accuracy: 0.9250\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2009 - accuracy: 0.9252 - val_loss: 0.1861 - val_accuracy: 0.9302\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1967 - accuracy: 0.9270 - val_loss: 0.1925 - val_accuracy: 0.9290\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1926 - accuracy: 0.9277 - val_loss: 0.1936 - val_accuracy: 0.9280\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1862 - accuracy: 0.9314 - val_loss: 0.1877 - val_accuracy: 0.9292\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1828 - accuracy: 0.9319 - val_loss: 0.1592 - val_accuracy: 0.9404\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1774 - accuracy: 0.9335 - val_loss: 0.1596 - val_accuracy: 0.9418\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1718 - accuracy: 0.9355 - val_loss: 0.1514 - val_accuracy: 0.9428\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1693 - accuracy: 0.9364 - val_loss: 0.1650 - val_accuracy: 0.9384\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1667 - accuracy: 0.9378 - val_loss: 0.1448 - val_accuracy: 0.9466\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1599 - accuracy: 0.9408 - val_loss: 0.1459 - val_accuracy: 0.9428\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1583 - accuracy: 0.9412 - val_loss: 0.1545 - val_accuracy: 0.9406\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1554 - accuracy: 0.9413 - val_loss: 0.1617 - val_accuracy: 0.9386\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1505 - accuracy: 0.9438 - val_loss: 0.1318 - val_accuracy: 0.9500\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1475 - accuracy: 0.9454 - val_loss: 0.1351 - val_accuracy: 0.9504\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3655884265899658, 0.8888000249862671]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=30, batch_size=64, validation_data=(X_valid, y_valid))\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pregunta 7.3 (0.20 puntos)**\n",
    "* ¿Por qué piensas que ocurre esto? Explica tu respuesta y da el nombre de este efecto si lo conoces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fs0fjzH4bmSR"
   },
   "source": [
    "Tu respuesta a la pregunta 7.3 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*El accuracy de ambos modelos con 15 y 30 epochs respectivamente, es practicamente el mismo. Lo que sí podemos apreciar es un empeoramiento del coste a mayor número de epochs. Esto puede significar que el modelo está sufriendo de overfitting ya que no hay suficientes datos como para dedicarles tanto tiempo y ciclos de aprendizaje para  aprenderlos.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlIgNG4Yb_N6"
   },
   "source": [
    "## 8: Early stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06rrpDXqupAA"
   },
   "source": [
    "En el ejercicio anterior, cuando entrenabas con epoch extras, tenías un problema en el que tu pérdida podía cambiar. Puede que te haya llevado un poco de tiempo esperar a que el entrenamiento lo hiciera,  y puede que hayas pensado \"¿no estaría bien si pudiera parar el entrenamiento cuando alcance un valor deseado?\", es decir, una precisión del 85% podría ser suficiente para ti, y si alcanzas eso después de 3 epoch, ¿por qué sentarte a esperar a que termine muchas más épocas? Como cualquier otro programa existen formas de parar la ejecución\n",
    "\n",
    "A partir del código de ejemplo, hacer una nueva función que tenga en cuenta la perdida (loss) y que pueda parar el código para evitar que ocurra el efeto secundario que vimos en el ejercicio 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "b5UwceFUG4ic"
   },
   "outputs": [],
   "source": [
    "### Ejemplo de código\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('accuracy')> 0.85):\n",
    "                  print(\"\\nAlcanzado el 85% de precisión, se cancela el entrenamiento!!\")\n",
    "                  self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "29LSfdOvc270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "Epoch 1/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5211 - accuracy: 0.8179\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.8613\n",
      "Alcanzado el 85% de precisión, se cancela el entrenamiento!!\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3870 - accuracy: 0.8613\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4076 - accuracy: 0.8521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40757325291633606, 0.8521000146865845]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "### Tu código de la función callback para parar el entrenamiento de la red neuronal al 40% de loss aqui: ###\n",
    "\n",
    "callbacks = myCallback()\n",
    "# mnist = tf.keras.datasets.fashion_mnist\n",
    "# (training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# training_images = training_images/255.0\n",
    "# test_images = test_images/255.0\n",
    "\n",
    "\n",
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=50, batch_size=64, callbacks=[callbacks])\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Bjd8wGKccrn"
   },
   "source": [
    "**Ejercicio 8 *(0.75 puntos)***: Completa el siguiente código con una clase callback que una vez alcanzado el 40% de perdida detenga el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ejemplo de código\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('loss') < 0.4):\n",
    "                  print(\"\\nAlcanzado el 40 de pérdida, se cancela el entrenamiento!!\")\n",
    "                  self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "Epoch 1/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5188 - accuracy: 0.8197\n",
      "Epoch 2/50\n",
      "931/938 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8613\n",
      "Alcanzado el 40 de pérdida, se cancela el entrenamiento!!\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3884 - accuracy: 0.8613\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3992 - accuracy: 0.8582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.399247407913208, 0.8582000136375427]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "### Tu código de la función callback para parar el entrenamiento de la red neuronal al 40% de loss aqui: ###\n",
    "\n",
    "callbacks = myCallback()\n",
    "# mnist = tf.keras.datasets.fashion_mnist\n",
    "# (training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# training_images = training_images/255.0\n",
    "# test_images = test_images/255.0\n",
    "\n",
    "\n",
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=50, batch_size=64, callbacks=[callbacks])\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_yZ9B8gTFqR"
   },
   "source": [
    "## 9. Unidades de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuVNxmXSTFqR"
   },
   "source": [
    "En este ejercicio, vamos a evaluar la importancia de utilizar las unidades de activación adecuadas. Como hemos visto en clase, funciones de activación como sigmoid han dejado de utilizarse en favor de otras como ReLU.\n",
    "\n",
    "**Ejercicio 9 *(0.75 puntos)***: Partiendo de una red sencilla como la desarrollada en el Trabajo 1, escribir un breve análisis comparando la utilización de unidades sigmoid y ReLU (por ejemplo, se pueden comentar aspectos como velocidad de convergencia, métricas obtenidas...). Explicar por qué pueden darse estas diferencias. Opcionalmente, comparar con otras activaciones disponibles en Keras.\n",
    "\n",
    "*Pista: Usando redes más grandes se hace más sencillo apreciar las diferencias. Es mejor utilizar al menos 3 o 4 capas densas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ejemplo de código\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs={}):\n",
    "            perdida = 0.4\n",
    "            precision = 0.9\n",
    "            if(logs.get('accuracy') > precision and logs.get('loss') < perdida):\n",
    "                  print(\"\\nAlcanzado el {}% de precisión y {}% de pérdida, se cancela el entrenamiento!!\".format(precision, perdida))\n",
    "                  self.model.stop_training = True\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "hoYUajTuTFqS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 5s 4ms/step - loss: 0.5087 - accuracy: 0.8177\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3680 - accuracy: 0.8662\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3363 - accuracy: 0.8766\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3103 - accuracy: 0.8849\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2915 - accuracy: 0.8921\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2802 - accuracy: 0.8943\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2681 - accuracy: 0.8991\n",
      "Epoch 8/50\n",
      "929/938 [============================>.] - ETA: 0s - loss: 0.2553 - accuracy: 0.9035\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2553 - accuracy: 0.9035\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3434407114982605, 0.878600001335144]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=50, batch_size=64, callbacks=[callbacks])\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 5s 4ms/step - loss: 0.9066 - accuracy: 0.6541\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4692 - accuracy: 0.8319\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3912 - accuracy: 0.8585\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3563 - accuracy: 0.8720\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3341 - accuracy: 0.8791\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3164 - accuracy: 0.8847\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3008 - accuracy: 0.8905\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2897 - accuracy: 0.8941\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2796 - accuracy: 0.8991\n",
      "Epoch 10/50\n",
      "932/938 [============================>.] - ETA: 0s - loss: 0.2686 - accuracy: 0.9014\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2689 - accuracy: 0.9012\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3438 - accuracy: 0.8801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34376025199890137, 0.8801000118255615]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(128, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(128, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(128, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=50, batch_size=64, callbacks=[callbacks])\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.5143 - accuracy: 0.8136\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.3972 - accuracy: 0.8548\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.3592 - accuracy: 0.8676\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.3415 - accuracy: 0.8737\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.3240 - accuracy: 0.8812\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.3083 - accuracy: 0.8860\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.3021 - accuracy: 0.8863\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.2882 - accuracy: 0.8929\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.2813 - accuracy: 0.8969\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.2752 - accuracy: 0.8968\n",
      "Epoch 11/50\n",
      "934/938 [============================>.] - ETA: 0s - loss: 0.2638 - accuracy: 0.9003\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.2638 - accuracy: 0.9003\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3768 - accuracy: 0.8725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3768080174922943, 0.8725000023841858]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(512, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(512, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(512, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(512, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=50, batch_size=64, callbacks=[callbacks])\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La comparación entre el uso de la función de activación sigmoid y ReLU en una red neuronal sencilla puede tener varias diferencias en términos de velocidad de convergencia y rendimiento del modelo.*\n",
    "\n",
    "*En general, la función de activación ReLU se ha demostrado que converge más rápido en comparación con la función sigmoid en la mayoría de los casos, esto se debe principalmente a que la función ReLU no presenta saturación en la región positiva, es decir, la derivada nunca es cero, mientras que en sigmoid si hay una región en la que la derivada es muy pequeña (cercana a cero) y puede hacer que el entrenamiento sea lento.*\n",
    "\n",
    "*Además, la función ReLU ha demostrado ser más efectiva en la prevención del sobreajuste (overfitting), lo que se debe a que la función ReLU puede disminuir la correlación entre las neuronas adyacentes, lo que reduce la dependencia de las neuronas entre sí y, por lo tanto, ayuda a prevenir el sobreajuste.*\n",
    "\n",
    "*En términos de rendimiento del modelo, la función ReLU también puede proporcionar resultados ligeramente mejores en comparación con la función sigmoid. Esto se debe a que la función ReLU permite la propagación de gradientes más fuertes en la red neuronal, lo que puede mejorar la capacidad de la red para aprender representaciones abstractas de los datos.*\n",
    "\n",
    "*En cuanto a otras funciones de activación disponibles en Keras, hay muchas opciones diferentes, cada una con sus ventajas y desventajas. Por ejemplo, la función de activación tanh (tangente hiperbólica) se utiliza comúnmente en redes neuronales porque puede proporcionar resultados ligeramente mejores que sigmoid en algunos casos. También hay otras funciones de activación como la función softmax, la función ELU (exponential linear unit) y la función Swish, que han demostrado ser efectivas en diferentes aplicaciones.*\n",
    "\n",
    "*Sintetizando, la función de activación ReLU puede ser una mejor opción en comparación con sigmoid en la mayoría de los casos, debido a su rapidez de convergencia y capacidad para prevenir el sobreajuste. Sin embargo, es importante tener en cuenta que cada función de activación tiene sus propias ventajas y desventajas, y debe seleccionarse de acuerdo con la tarea específica que se esté abordando*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pu6RbUFKTFqT"
   },
   "source": [
    "## 10. Inicialización de parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Abmm05UPTFqU"
   },
   "source": [
    "En este ejercicio, vamos a evaluar la importancia de una correcta inicialización de parámetros en una red neuronal.\n",
    "\n",
    "**Ejercicio 10 *(0.75 puntos)***: Partiendo de una red similar a la del ejercicio anterior (usando ya ReLUs), comentar las diferencias que se aprecian en el entrenamiento al utilizar distintas estrategias de inicialización de parámetros. Para ello, inicializar todas las capas con las siguientes estrategias, disponibles en Keras, y analizar sus diferencias:\n",
    "\n",
    "* Inicialización con ceros.\n",
    "* Inicialización con una variable aleatoria normal.\n",
    "* Inicialización con los valores por defecto de Keras para una capa Dense (estrategia *glorot uniform*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Inicialización con ceros*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 4s 3ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.0986\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.3028 - accuracy: 0.0967 - val_loss: 2.3025 - val_accuracy: 0.1024\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3027 - val_accuracy: 0.0986\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.1008\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.1024\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3027 - accuracy: 0.0968 - val_loss: 2.3026 - val_accuracy: 0.1002\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3027 - accuracy: 0.0991 - val_loss: 2.3025 - val_accuracy: 0.0976\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3027 - accuracy: 0.0990 - val_loss: 2.3025 - val_accuracy: 0.1112\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3027 - accuracy: 0.0996 - val_loss: 2.3025 - val_accuracy: 0.0976\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.0986\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3025929927825928, 0.10000000149011612]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "\n",
    "    keras.layers.Dense(128,\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=keras.initializers.zeros,\n",
    "    ),\n",
    "\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=10, batch_size=64, callbacks=[callbacks], validation_data=(X_valid, y_valid))\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Si inicializamos los pesos del modelo a cero, cada neurona en la red neuronal tiene la misma salida, lo que significa que todas las neuronas de la capa oculta se comportarán de la misma manera. Como resultado, cada neurona en la capa oculta producirá la misma salida, lo que significa que todas las neuronas de la capa oculta se comportarán de la misma manera. Esto puede provocar que el modelo no aprenda correctamente y que la precisión sea muy baja.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Inicialización con una variable aleatoria normal.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 5s 4ms/step - loss: 0.5201 - accuracy: 0.8192 - val_loss: 0.4026 - val_accuracy: 0.8608\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3868 - accuracy: 0.8622 - val_loss: 0.3480 - val_accuracy: 0.8726\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3448 - accuracy: 0.8759 - val_loss: 0.3252 - val_accuracy: 0.8844\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3223 - accuracy: 0.8830 - val_loss: 0.2826 - val_accuracy: 0.8986\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.3023 - accuracy: 0.8915 - val_loss: 0.2685 - val_accuracy: 0.9010\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2899 - accuracy: 0.8936 - val_loss: 0.2670 - val_accuracy: 0.9014\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2765 - accuracy: 0.8995 - val_loss: 0.2860 - val_accuracy: 0.8924\n",
      "Epoch 8/20\n",
      "925/938 [============================>.] - ETA: 0s - loss: 0.2673 - accuracy: 0.9016\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2669 - accuracy: 0.9018 - val_loss: 0.2411 - val_accuracy: 0.9144\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3343 - accuracy: 0.8822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3343217670917511, 0.8822000026702881]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "\n",
    "    keras.layers.Dense(128,\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None),\n",
    "    ),\n",
    "\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=20, batch_size=64, callbacks=[callbacks], validation_data=(X_valid, y_valid))\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La inicialización con variables aleatorias asigna pesos iniciales aleatorios a cada neurona en la red. Esto puede mejorar significativamente el rendimiento del modelo, ya que cada neurona de la red tiene una salida diferente, lo que permite una mayor capacidad de aprendizaje. Además, la inicialización con variables aleatorias se puede ajustar para garantizar que los pesos iniciales sean de magnitud apropiada para el tamaño de la capa.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Inicialización con los valores por defecto de Keras para una capa Dense (estrategia *glorot uniform*)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.5208 - accuracy: 0.8195 - val_loss: 0.3914 - val_accuracy: 0.8652\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3895 - accuracy: 0.8612 - val_loss: 0.3424 - val_accuracy: 0.8750\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3486 - accuracy: 0.8739 - val_loss: 0.3054 - val_accuracy: 0.8906\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3230 - accuracy: 0.8829 - val_loss: 0.2976 - val_accuracy: 0.8924\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3033 - accuracy: 0.8893 - val_loss: 0.2698 - val_accuracy: 0.9018\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2904 - accuracy: 0.8918 - val_loss: 0.2570 - val_accuracy: 0.9058\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2778 - accuracy: 0.8978 - val_loss: 0.2530 - val_accuracy: 0.9062\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - ETA: 0s - loss: 0.2645 - accuracy: 0.9017\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2645 - accuracy: 0.9017 - val_loss: 0.2360 - val_accuracy: 0.9108\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33844298124313354, 0.8795999884605408]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "\n",
    "    keras.layers.Dense(128,\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=keras.initializers.glorot_uniform,\n",
    "    ),\n",
    "\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer= \"adam\",\n",
    "            metrics =[\"accuracy\"])\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=20, batch_size=64, callbacks=[callbacks], validation_data=(X_valid, y_valid))\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La inicialización por defecto utiliza una estrategia de inicialización específica para cada capa de la red neuronal, como la inicialización de Glorot o la inicialización de He. Estas estrategias de inicialización ajustan automáticamente los pesos iniciales para mejorar el rendimiento del modelo. En general, estas estrategias de inicialización por defecto son más efectivas que la inicialización con variables aleatorias y pueden proporcionar una precisión más alta y una convergencia más rápida.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqIAyVWrTFqV"
   },
   "source": [
    "## 11. Optimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcYj29hYTFqW"
   },
   "source": [
    "**Ejercicio 11 *(0.75 puntos)***: Partiendo de una red similar a la del ejercicio anterior (utilizando la mejor estrategia de inicialización observada), comparar y analizar las diferencias que se observan  al entrenar con varios de los optimizadores vistos en clase, incluyendo SGD como optimizador básico (se puede explorar el espacio de hiperparámetros de cada optimizador, aunque para optimizadores más avanzados del estilo de adam y RMSprop es buena idea dejar los valores por defecto provistos por Keras)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Para este apartado definiré una función con la configuración de las redes neuronales anteriores para ir variando en cada apartado el optimizador*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_optimizers(opt):\n",
    "    model= keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        # keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(len(np.unique(training_labels)), activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer= opt,\n",
    "                metrics =[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(training_images, training_labels, epochs=20, batch_size=32, callbacks=[callbacks], validation_data=(X_valid, y_valid))\n",
    "\n",
    "    return model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizadores = [\"SGD\", \"RMSProp\", \"Adam\", \"AdamW\", \"Adadelta\", \"Adagrad\", \"Adamax\", \"Adafactor\", \"Nadam\", \"Ftrl\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7816 - accuracy: 0.7376 - val_loss: 0.5490 - val_accuracy: 0.7994\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4958 - accuracy: 0.8263 - val_loss: 0.4318 - val_accuracy: 0.8484\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4414 - accuracy: 0.8459 - val_loss: 0.3940 - val_accuracy: 0.8656\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4101 - accuracy: 0.8555 - val_loss: 0.3726 - val_accuracy: 0.8730\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3876 - accuracy: 0.8640 - val_loss: 0.3626 - val_accuracy: 0.8724\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3692 - accuracy: 0.8682 - val_loss: 0.3480 - val_accuracy: 0.8792\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3538 - accuracy: 0.8739 - val_loss: 0.3310 - val_accuracy: 0.8856\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3425 - accuracy: 0.8769 - val_loss: 0.3270 - val_accuracy: 0.8852\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3324 - accuracy: 0.8805 - val_loss: 0.3155 - val_accuracy: 0.8900\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3220 - accuracy: 0.8833 - val_loss: 0.2979 - val_accuracy: 0.8958\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3142 - accuracy: 0.8868 - val_loss: 0.3079 - val_accuracy: 0.8890\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3074 - accuracy: 0.8882 - val_loss: 0.2927 - val_accuracy: 0.8974\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2986 - accuracy: 0.8906 - val_loss: 0.3049 - val_accuracy: 0.8880\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2928 - accuracy: 0.8932 - val_loss: 0.2787 - val_accuracy: 0.8992\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2857 - accuracy: 0.8953 - val_loss: 0.2653 - val_accuracy: 0.9032\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2804 - accuracy: 0.8978 - val_loss: 0.2590 - val_accuracy: 0.9100\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2751 - accuracy: 0.8989 - val_loss: 0.2534 - val_accuracy: 0.9116\n",
      "Epoch 18/20\n",
      "1869/1875 [============================>.] - ETA: 0s - loss: 0.2704 - accuracy: 0.9011\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2703 - accuracy: 0.9011 - val_loss: 0.2559 - val_accuracy: 0.9070\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3443 - accuracy: 0.8757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34432753920555115, 0.8756999969482422]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD = nn_optimizers(tf.keras.optimizers.SGD())\n",
    "SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5025 - accuracy: 0.8172 - val_loss: 0.3831 - val_accuracy: 0.8644\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3823 - accuracy: 0.8638 - val_loss: 0.3733 - val_accuracy: 0.8610\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3626 - accuracy: 0.8715 - val_loss: 0.3416 - val_accuracy: 0.8764\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3578 - accuracy: 0.8754 - val_loss: 0.3484 - val_accuracy: 0.8824\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3533 - accuracy: 0.8770 - val_loss: 0.3421 - val_accuracy: 0.8760\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3538 - accuracy: 0.8774 - val_loss: 0.3451 - val_accuracy: 0.8772\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3468 - accuracy: 0.8805 - val_loss: 0.3267 - val_accuracy: 0.8906\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3495 - accuracy: 0.8812 - val_loss: 0.2921 - val_accuracy: 0.9002\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3448 - accuracy: 0.8838 - val_loss: 0.2993 - val_accuracy: 0.8882\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3396 - accuracy: 0.8870 - val_loss: 0.2883 - val_accuracy: 0.8994\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3430 - accuracy: 0.8864 - val_loss: 0.3068 - val_accuracy: 0.8958\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3465 - accuracy: 0.8859 - val_loss: 0.3370 - val_accuracy: 0.8788\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3452 - accuracy: 0.8853 - val_loss: 0.3262 - val_accuracy: 0.8940\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3442 - accuracy: 0.8885 - val_loss: 0.2808 - val_accuracy: 0.9020\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3398 - accuracy: 0.8876 - val_loss: 0.4140 - val_accuracy: 0.8776\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3396 - accuracy: 0.8890 - val_loss: 0.3270 - val_accuracy: 0.8888\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3386 - accuracy: 0.8913 - val_loss: 0.2752 - val_accuracy: 0.9082\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3288 - accuracy: 0.8921 - val_loss: 0.3035 - val_accuracy: 0.8934\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3309 - accuracy: 0.8931 - val_loss: 0.3301 - val_accuracy: 0.8914\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3258 - accuracy: 0.8943 - val_loss: 0.2546 - val_accuracy: 0.9070\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4678 - accuracy: 0.8732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4677613377571106, 0.873199999332428]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSProp = nn_optimizers(\"rmsprop\")\n",
    "RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4874 - accuracy: 0.8227 - val_loss: 0.3558 - val_accuracy: 0.8730\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3677 - accuracy: 0.8637 - val_loss: 0.3267 - val_accuracy: 0.8780\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3340 - accuracy: 0.8754 - val_loss: 0.2960 - val_accuracy: 0.8912\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3081 - accuracy: 0.8849 - val_loss: 0.3039 - val_accuracy: 0.8902\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2913 - accuracy: 0.8910 - val_loss: 0.2820 - val_accuracy: 0.8944\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2757 - accuracy: 0.8970 - val_loss: 0.2493 - val_accuracy: 0.9054\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2647 - accuracy: 0.8997 - val_loss: 0.2328 - val_accuracy: 0.9120\n",
      "Epoch 8/20\n",
      "1859/1875 [============================>.] - ETA: 0s - loss: 0.2510 - accuracy: 0.9055\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2511 - accuracy: 0.9054 - val_loss: 0.2197 - val_accuracy: 0.9172\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3199 - accuracy: 0.8868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.319913774728775, 0.8867999911308289]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adam = nn_optimizers(tf.keras.optimizers.Adam())\n",
    "Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4870 - accuracy: 0.8234 - val_loss: 0.3504 - val_accuracy: 0.8752\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3655 - accuracy: 0.8658 - val_loss: 0.3247 - val_accuracy: 0.8818\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3298 - accuracy: 0.8783 - val_loss: 0.3101 - val_accuracy: 0.8864\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3075 - accuracy: 0.8851 - val_loss: 0.3001 - val_accuracy: 0.8852\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2910 - accuracy: 0.8914 - val_loss: 0.2495 - val_accuracy: 0.9106\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2777 - accuracy: 0.8960 - val_loss: 0.2517 - val_accuracy: 0.9068\n",
      "Epoch 7/20\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.2654 - accuracy: 0.9008\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2654 - accuracy: 0.9008 - val_loss: 0.2414 - val_accuracy: 0.9066\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.8803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34151172637939453, 0.880299985408783]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdamW = nn_optimizers(tf.keras.optimizers.AdamW())\n",
    "AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.2224 - accuracy: 0.1685 - val_loss: 2.1186 - val_accuracy: 0.3124\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.0153 - accuracy: 0.4661 - val_loss: 1.9036 - val_accuracy: 0.5608\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.7883 - accuracy: 0.5984 - val_loss: 1.6624 - val_accuracy: 0.6326\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5580 - accuracy: 0.6384 - val_loss: 1.4416 - val_accuracy: 0.6576\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3610 - accuracy: 0.6537 - val_loss: 1.2656 - val_accuracy: 0.6700\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2103 - accuracy: 0.6624 - val_loss: 1.1368 - val_accuracy: 0.6774\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1015 - accuracy: 0.6737 - val_loss: 1.0441 - val_accuracy: 0.6872\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0222 - accuracy: 0.6844 - val_loss: 0.9759 - val_accuracy: 0.6998\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9629 - accuracy: 0.6959 - val_loss: 0.9239 - val_accuracy: 0.7118\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9167 - accuracy: 0.7064 - val_loss: 0.8826 - val_accuracy: 0.7182\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8793 - accuracy: 0.7140 - val_loss: 0.8487 - val_accuracy: 0.7288\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8481 - accuracy: 0.7215 - val_loss: 0.8202 - val_accuracy: 0.7374\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8219 - accuracy: 0.7282 - val_loss: 0.7957 - val_accuracy: 0.7426\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7991 - accuracy: 0.7330 - val_loss: 0.7747 - val_accuracy: 0.7476\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7792 - accuracy: 0.7384 - val_loss: 0.7561 - val_accuracy: 0.7514\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7614 - accuracy: 0.7433 - val_loss: 0.7392 - val_accuracy: 0.7574\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7453 - accuracy: 0.7485 - val_loss: 0.7238 - val_accuracy: 0.7606\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7307 - accuracy: 0.7523 - val_loss: 0.7100 - val_accuracy: 0.7642\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7174 - accuracy: 0.7565 - val_loss: 0.6972 - val_accuracy: 0.7672\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7052 - accuracy: 0.7599 - val_loss: 0.6852 - val_accuracy: 0.7706\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7150 - accuracy: 0.7511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7150465250015259, 0.7511000037193298]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adadelta = nn_optimizers(tf.keras.optimizers.Adadelta())\n",
    "Adadelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1352 - accuracy: 0.6434 - val_loss: 0.7317 - val_accuracy: 0.7562\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6716 - accuracy: 0.7750 - val_loss: 0.6036 - val_accuracy: 0.8016\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5881 - accuracy: 0.8041 - val_loss: 0.5527 - val_accuracy: 0.8130\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5448 - accuracy: 0.8169 - val_loss: 0.5157 - val_accuracy: 0.8288\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5177 - accuracy: 0.8247 - val_loss: 0.4930 - val_accuracy: 0.8340\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4984 - accuracy: 0.8313 - val_loss: 0.4791 - val_accuracy: 0.8420\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4841 - accuracy: 0.8346 - val_loss: 0.4665 - val_accuracy: 0.8448\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4732 - accuracy: 0.8385 - val_loss: 0.4550 - val_accuracy: 0.8488\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4638 - accuracy: 0.8410 - val_loss: 0.4464 - val_accuracy: 0.8536\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4561 - accuracy: 0.8436 - val_loss: 0.4384 - val_accuracy: 0.8552\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4495 - accuracy: 0.8456 - val_loss: 0.4347 - val_accuracy: 0.8574\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4436 - accuracy: 0.8472 - val_loss: 0.4272 - val_accuracy: 0.8574\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4385 - accuracy: 0.8490 - val_loss: 0.4237 - val_accuracy: 0.8592\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4337 - accuracy: 0.8504 - val_loss: 0.4215 - val_accuracy: 0.8610\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4295 - accuracy: 0.8520 - val_loss: 0.4146 - val_accuracy: 0.8608\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4255 - accuracy: 0.8530 - val_loss: 0.4111 - val_accuracy: 0.8622\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4219 - accuracy: 0.8542 - val_loss: 0.4077 - val_accuracy: 0.8640\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4182 - accuracy: 0.8552 - val_loss: 0.4061 - val_accuracy: 0.8650\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4155 - accuracy: 0.8558 - val_loss: 0.4027 - val_accuracy: 0.8666\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4125 - accuracy: 0.8572 - val_loss: 0.3986 - val_accuracy: 0.8686\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4445 - accuracy: 0.8422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44447749853134155, 0.842199981212616]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adagrad = nn_optimizers(tf.keras.optimizers.Adagrad())\n",
    "Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5297 - accuracy: 0.8129 - val_loss: 0.4153 - val_accuracy: 0.8546\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3897 - accuracy: 0.8607 - val_loss: 0.3646 - val_accuracy: 0.8710\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3504 - accuracy: 0.8733 - val_loss: 0.3831 - val_accuracy: 0.8514\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3244 - accuracy: 0.8820 - val_loss: 0.3013 - val_accuracy: 0.8932\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3077 - accuracy: 0.8872 - val_loss: 0.2710 - val_accuracy: 0.8998\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2930 - accuracy: 0.8919 - val_loss: 0.2599 - val_accuracy: 0.9030\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2785 - accuracy: 0.8963 - val_loss: 0.2641 - val_accuracy: 0.9034\n",
      "Epoch 8/20\n",
      "1871/1875 [============================>.] - ETA: 0s - loss: 0.2665 - accuracy: 0.9014\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2666 - accuracy: 0.9014 - val_loss: 0.2588 - val_accuracy: 0.9022\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3483 - accuracy: 0.8742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34832513332366943, 0.8741999864578247]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adamax = nn_optimizers(tf.keras.optimizers.Adamax())\n",
    "Adamax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adafactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.3026 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1112\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.0986\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.0986\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0972 - val_loss: 2.3026 - val_accuracy: 0.0986\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.0986\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0960 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.0986\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0962 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0962 - val_loss: 2.3026 - val_accuracy: 0.0914\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.302589178085327, 0.10000000149011612]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adafactor = nn_optimizers(tf.keras.optimizers.Adafactor())\n",
    "Adafactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 8s 3ms/step - loss: 0.4705 - accuracy: 0.8299 - val_loss: 0.3768 - val_accuracy: 0.8544\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3569 - accuracy: 0.8692 - val_loss: 0.3047 - val_accuracy: 0.8896\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3263 - accuracy: 0.8800 - val_loss: 0.2736 - val_accuracy: 0.8956\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3025 - accuracy: 0.8869 - val_loss: 0.2779 - val_accuracy: 0.8976\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2878 - accuracy: 0.8921 - val_loss: 0.2675 - val_accuracy: 0.9024\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2732 - accuracy: 0.8973 - val_loss: 0.2483 - val_accuracy: 0.9092\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.2606 - accuracy: 0.9026\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2606 - accuracy: 0.9026 - val_loss: 0.2439 - val_accuracy: 0.9106\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.348713219165802, 0.8773999810218811]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nadam = nn_optimizers(tf.keras.optimizers.Nadam())\n",
    "Nadam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ftrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.3026 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3025858402252197, 0.10000000149011612]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ftrl = nn_optimizers(tf.keras.optimizers.Ftrl())\n",
    "Ftrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Resumen de los resultados de los optimizadores*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión del modelo con el optimizador SGD es: 0.8756999969482422 \n",
      "La precisión del modelo con el optimizador RMSProp es: 0.873199999332428 \n",
      "La precisión del modelo con el optimizador Adam es: 0.8867999911308289 \n",
      "La precisión del modelo con el optimizador AdamW es: 0.880299985408783 \n",
      "La precisión del modelo con el optimizador Adadelta es: 0.7511000037193298 \n",
      "La precisión del modelo con el optimizador Adagrad es: 0.842199981212616 \n",
      "La precisión del modelo con el optimizador Adamax es: 0.8741999864578247 \n",
      "La precisión del modelo con el optimizador Adafactor es: 0.10000000149011612 \n",
      "La precisión del modelo con el optimizador Nadam es: 0.8773999810218811 \n",
      "La precisión del modelo con el optimizador Ftrl es: 0.10000000149011612 \n",
      "--------------------------------------------------------------------------\n",
      "El mejor optimizador ha resultado ser Adam con un accuracy de: 0.8867999911308289\n"
     ]
    }
   ],
   "source": [
    "diccionario_optimizadores = {\n",
    "    \"SGD\": SGD[1],\n",
    "    \"RMSProp\": RMSProp[1],\n",
    "    \"Adam\": Adam[1],\n",
    "    \"AdamW\": AdamW[1],  \n",
    "    \"Adadelta\": Adadelta[1],\n",
    "    \"Adagrad\" : Adagrad[1],\n",
    "    \"Adamax\": Adamax[1],\n",
    "    \"Adafactor\": Adafactor[1],\n",
    "    \"Nadam\": Nadam[1],\n",
    "    \"Ftrl\": Ftrl[1]\n",
    "}\n",
    "best_optimizer = 0\n",
    "best_optimizer_tag = 0\n",
    "for i, j in diccionario_optimizadores.items():\n",
    "    print(\"La precisión del modelo con el optimizador {} es: {} \".format(i, j))\n",
    "    if best_optimizer < j:\n",
    "        best_optimizer = j\n",
    "        best_optimizer_tag = i\n",
    "\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(\"El mejor optimizador ha resultado ser {} con un accuracy de: {}\".format(best_optimizer_tag, best_optimizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkfTFoJOTFqZ"
   },
   "source": [
    "## 12. Regularización y red final "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6CQhK7ZTFqZ"
   },
   "source": [
    "**Ejercicio 12 *(1 punto)***: Entrenar una red final que sea capaz de obtener una accuracy en el validation set cercana al 90%. Para ello, combinar todo lo aprendido anteriormente y utilizar técnicas de regularización para evitar overfitting. Algunos de los elementos que pueden tenerse en cuenta son los siguientes.\n",
    "\n",
    "* Número de capas y neuronas por capa\n",
    "* Optimizadores y sus parámetros\n",
    "* Batch size\n",
    "* Unidades de activación\n",
    "* Uso de capas dropout, regularización L2, regularización L1...\n",
    "* Early stopping (se puede aplicar como un callback de Keras, o se puede ver un poco \"a ojo\" cuándo el modelo empieza a caer en overfitting y seleccionar el número de epochs necesarias)\n",
    "* Batch normalization\n",
    "\n",
    "Si los modelos entrenados anteriormente ya se acercaban al valor requerido de accuracy, probar distintas estrategias igualmente y comentar los resultados.\n",
    "\n",
    "Explicar brevemente la estrategia seguida y los modelos probados para obtener el modelo final, que debe verse entrenado en este Notebook. No es necesario guardar el entrenamiento de todos los modelos que se han probado, es suficiente con explicar cómo se ha llegado al modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_resultado = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "AUJ5AtunTFqa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4879 - accuracy: 0.8223 - val_loss: 0.3910 - val_accuracy: 0.8562\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3674 - accuracy: 0.8637 - val_loss: 0.3303 - val_accuracy: 0.8784\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3319 - accuracy: 0.8776 - val_loss: 0.3031 - val_accuracy: 0.8880\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3115 - accuracy: 0.8847 - val_loss: 0.2723 - val_accuracy: 0.8964\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2916 - accuracy: 0.8921 - val_loss: 0.2497 - val_accuracy: 0.9076\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2763 - accuracy: 0.8974 - val_loss: 0.2547 - val_accuracy: 0.9024\n",
      "Epoch 7/30\n",
      "1867/1875 [============================>.] - ETA: 0s - loss: 0.2660 - accuracy: 0.9000\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2661 - accuracy: 0.9001 - val_loss: 0.2340 - val_accuracy: 0.9132\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3312 - accuracy: 0.8807\n",
      "\n",
      "\n",
      "Mejor resultado de accuracy obtenido: 0.8806999921798706\n",
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4918 - accuracy: 0.8218 - val_loss: 0.3645 - val_accuracy: 0.8686\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3692 - accuracy: 0.8640 - val_loss: 0.3494 - val_accuracy: 0.8718\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3343 - accuracy: 0.8755 - val_loss: 0.2830 - val_accuracy: 0.8936\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3083 - accuracy: 0.8858 - val_loss: 0.2919 - val_accuracy: 0.8888\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2921 - accuracy: 0.8908 - val_loss: 0.3042 - val_accuracy: 0.8862\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2791 - accuracy: 0.8949 - val_loss: 0.2534 - val_accuracy: 0.9036\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2661 - accuracy: 0.8999 - val_loss: 0.2420 - val_accuracy: 0.9042\n",
      "Epoch 8/30\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.2565 - accuracy: 0.9027\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2566 - accuracy: 0.9027 - val_loss: 0.2749 - val_accuracy: 0.8962\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3881 - accuracy: 0.8616\n",
      "\n",
      "\n",
      "Mejor resultado de accuracy obtenido: 0.8806999921798706\n",
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4914 - accuracy: 0.8207 - val_loss: 0.3569 - val_accuracy: 0.8700\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3664 - accuracy: 0.8657 - val_loss: 0.3352 - val_accuracy: 0.8720\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3334 - accuracy: 0.8766 - val_loss: 0.2965 - val_accuracy: 0.8928\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3089 - accuracy: 0.8848 - val_loss: 0.2759 - val_accuracy: 0.8990\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2912 - accuracy: 0.8909 - val_loss: 0.2603 - val_accuracy: 0.8996\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2781 - accuracy: 0.8958 - val_loss: 0.2593 - val_accuracy: 0.9006\n",
      "Epoch 7/30\n",
      "1860/1875 [============================>.] - ETA: 0s - loss: 0.2654 - accuracy: 0.9011\n",
      "Alcanzado el 0.9% de precisión y 0.4% de pérdida, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2651 - accuracy: 0.9013 - val_loss: 0.2362 - val_accuracy: 0.9054\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3363 - accuracy: 0.8840\n",
      "\n",
      "\n",
      "Mejor resultado de accuracy obtenido: 0.8840000033378601\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    model= keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[len(training_images[0]), len(training_images[1])]),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    # keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(len(np.unique(training_labels)), activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer= best_optimizer_tag,\n",
    "                metrics =[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(training_images, training_labels, epochs=30, batch_size=32, callbacks=[callbacks], validation_data=(X_valid, y_valid))\n",
    "\n",
    "    resultado = model.evaluate(test_images, test_labels)\n",
    "\n",
    "\n",
    "    if mejor_resultado < resultado[1]:\n",
    "        mejor_resultado = resultado[1]\n",
    "    print(\"\\n\")\n",
    "    print(\"Mejor resultado de accuracy obtenido: {}\".format(mejor_resultado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FIN DEL CUADERNO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
